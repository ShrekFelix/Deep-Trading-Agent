{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MidtermCode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShrekFelix/Deep-Trading-Agent/blob/master/MidtermCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2sNvsc8OaKc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2RwoFIb_dbIF",
        "colab_type": "code",
        "outputId": "55091bc2-1143-472c-ec4b-07add01e6ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "bitstamp = pd.read_csv('bitstampUSD_1-min_data_2012-01-01_to_2018-06-27.csv')\n",
        "bitstamp.drop(labels='Timestamp', axis=1, inplace=True)\n",
        "bitstamp = bitstamp[2500000:]\n",
        "bitstamp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume_(BTC)</th>\n",
              "      <th>Volume_(Currency)</th>\n",
              "      <th>Weighted_Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2500000</th>\n",
              "      <td>609.87</td>\n",
              "      <td>609.87</td>\n",
              "      <td>609.41</td>\n",
              "      <td>609.41</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>2560.068344</td>\n",
              "      <td>609.540082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500001</th>\n",
              "      <td>609.87</td>\n",
              "      <td>609.87</td>\n",
              "      <td>609.41</td>\n",
              "      <td>609.41</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>2560.068344</td>\n",
              "      <td>609.540082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500002</th>\n",
              "      <td>609.87</td>\n",
              "      <td>609.87</td>\n",
              "      <td>609.41</td>\n",
              "      <td>609.41</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>2560.068344</td>\n",
              "      <td>609.540082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500003</th>\n",
              "      <td>610.97</td>\n",
              "      <td>610.97</td>\n",
              "      <td>610.97</td>\n",
              "      <td>610.97</td>\n",
              "      <td>0.018135</td>\n",
              "      <td>11.080002</td>\n",
              "      <td>610.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500004</th>\n",
              "      <td>610.97</td>\n",
              "      <td>610.97</td>\n",
              "      <td>610.97</td>\n",
              "      <td>610.97</td>\n",
              "      <td>0.018135</td>\n",
              "      <td>11.080002</td>\n",
              "      <td>610.970000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Open    High     Low   Close  Volume_(BTC)  Volume_(Currency)  \\\n",
              "2500000  609.87  609.87  609.41  609.41      4.200000        2560.068344   \n",
              "2500001  609.87  609.87  609.41  609.41      4.200000        2560.068344   \n",
              "2500002  609.87  609.87  609.41  609.41      4.200000        2560.068344   \n",
              "2500003  610.97  610.97  610.97  610.97      0.018135          11.080002   \n",
              "2500004  610.97  610.97  610.97  610.97      0.018135          11.080002   \n",
              "\n",
              "         Weighted_Price  \n",
              "2500000      609.540082  \n",
              "2500001      609.540082  \n",
              "2500002      609.540082  \n",
              "2500003      610.970000  \n",
              "2500004      610.970000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "vPcgBxjlOrEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for faster numpy concat\n",
        "b = np.array(bitstamp)\n",
        "a = b.reshape((-1))\n",
        "n = 24*60*60\n",
        "X = [a[i:i+n*7] for i in range(0,len(a) - 2*n*7,7)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NxpIQgwqLyTO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###code to generate y\n",
        "def getY(x,n):\n",
        "    x_num=len(x)\n",
        "    y=[]\n",
        "    for i in range(n,x_num-n):\n",
        "        temp=max(x[i:i+n][1])\n",
        "        temp=temp+min(x[i:i+n][2])\n",
        "        temp=temp-2*x[i+n-1][3]\n",
        "        temp=temp/x[i+n-1][3]\n",
        "        y.append(temp)\n",
        "    return y\n",
        "y=getY(b,n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-VmQxmiRVDXf",
        "colab_type": "code",
        "outputId": "53b0ae69-6100-4b98-bb9a-73752254a15a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# test shuffler\n",
        "\n",
        "X=[np.array([1,2,3]), np.array([2,3,4]), np.array([3,4,5])]\n",
        "y = [1,2, 3]\n",
        "\n",
        "shuffled = list(zip(X,y))\n",
        "random.shuffle(shuffled)\n",
        "print(shuffled)\n",
        "X1, y1 = list(zip(*shuffled))\n",
        "print(list(X1))\n",
        "print(list(y1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(array([3, 4, 5]), 3), (array([2, 3, 4]), 2), (array([1, 2, 3]), 1)]\n",
            "[array([3, 4, 5]), array([2, 3, 4]), array([1, 2, 3])]\n",
            "[3, 2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4gYih3JXq-xG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class dataGenerator():\n",
        "    def __init__(self,X,y):\n",
        "        import random\n",
        "        self.data_num=len(X)\n",
        "        shuffled = list(zip(X,y))\n",
        "        random.shuffle(shuffled)\n",
        "        self.X, self.y = list(zip(*shuffled))\n",
        "        self.X = list(self.X)\n",
        "        self.y = list(y)\n",
        "        self.iter=0\n",
        "    \n",
        "    def get_batch(self,n):\n",
        "        temp = self.iter\n",
        "        self.iter += n\n",
        "        self.iter %= self.data_num\n",
        "        if self.iter < temp:\n",
        "            self.iter %= self.data_numss\n",
        "            return np.append(self.X[temp:], self.X[:self.iter], axis = 0), np.append(self.y[temp:], self.y[:self.iter], axis = 0)\n",
        "        else:\n",
        "            #self.iter %= self.data_num\n",
        "            return self.X[temp:self.iter], self.y[temp:self.iter]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xoBGcBXYnc0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dg=dataGenerator(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3tJtzZJnhK5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tempx,tempy=dg.get_batch(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xaUVbqTqVlE",
        "colab_type": "code",
        "outputId": "11619c0a-329a-4ead-9067-364b03ab04bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tempy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1.2470509412973756, -1.2467240036952787]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "w984_Pa2o8UQ",
        "colab_type": "code",
        "outputId": "c63eaf3f-0e12-4a91-ee62-a1972b377d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(X[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "9l0sh6IjpLXq",
        "colab_type": "code",
        "outputId": "14a6eeff-628c-4ea6-b01c-88dc8cfaaaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "temp = X[0]\n",
        "temp = temp.reshape(-1,7,1)\n",
        "temp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86400, 7, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "hKwJdHQNRzwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(X)):\n",
        "  X[i] = X[i].reshape(-1,7,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IuuWCOh5kxGm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(y)):\n",
        "  y[i] = y[i].reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqAUVWobk1rD",
        "colab_type": "code",
        "outputId": "09a79b56-9a44-4fa8-fd99-7c9b2f3a29ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "mLIqrzeyiIgb",
        "colab_type": "code",
        "outputId": "d5008838-d59b-4939-f7b0-ec06a50852e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86400, 7, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "iN3ZS6nQZuli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ]
    },
    {
      "metadata": {
        "id": "vPNhGQd0Zsgz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reduction: decrease in output resolution\n",
        "#inception: output same dim\n",
        " \n",
        "images_path = \"data/MNIST_train_images.gz\"\n",
        "labels_path = \"data/MNIST_train_labels.gz\"\n",
        "export_path = \"saved_model/\"\n",
        "ckpt_path   = \"tmp/ckpt\"\n",
        " \n",
        "#mnist = MNISTData(images_path, labels_path)\n",
        "#validate_set, train_set = mnist.split(5000)\n",
        "\n",
        "def main():\n",
        "    tf.reset_default_graph()\n",
        "    model = InceptionModel([None, 86400, 7, 1], [None, 1])\n",
        "    model.train(dataGenerator(X, y), epochs=6875, keep_prob = 0.8)\n",
        "    #img, label = validate_set.get_batch(85)\n",
        "    #result = model.classify(img)\n",
        "    #result = model.classify(generateModelTestData(2))\n",
        "    result = model.classify(X)\n",
        "    print(np.argmax(result, axis=1))\n",
        "    print(np.argmax(y, axis=1))\n",
        "    correct_prediction = np.equal(np.argmax(result, 1), np.argmax(y, 1))\n",
        "    accuracy = np.sum(correct_prediction) / correct_prediction.size\n",
        "    print(correct_prediction)\n",
        "    print(accuracy)\n",
        "    \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2FYuBNbkGQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "S2gRQc-imCwz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generateModelTestData(n):\n",
        "    x=np.random.uniform(-5,5,size=(n,86400*7))\n",
        "    y=np.ones(n)\n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rGtkDS-HpRIe",
        "colab_type": "code",
        "outputId": "579eede3-bad9-4123-8763-44f06d8c05ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stem\n",
            "(?, 1349, 7, 384)\n",
            "inception_a\n",
            "(?, 1349, 7, 384)\n",
            "inception_a\n",
            "(?, 1349, 7, 384)\n",
            "inception_a\n",
            "(?, 1349, 7, 384)\n",
            "inception_a\n",
            "(?, 1349, 7, 384)\n",
            "reduction_a\n",
            "(?, 449, 7, 1024)\n",
            "inception_b\n",
            "(1, 223, 7, 1024)\n",
            "inception_b\n",
            "(1, 223, 7, 1024)\n",
            "inception_b\n",
            "(1, 223, 7, 1024)\n",
            "inception_b\n",
            "(1, 223, 7, 1024)\n",
            "inception_b\n",
            "(1, 223, 7, 1024)\n",
            "inception_b\n",
            "(1, 223, 7, 1024)\n",
            "inception_b\n",
            "(1, 223, 7, 1024)\n",
            "reduction_b\n",
            "(1, 74, 7, 1536)\n",
            "inception_c\n",
            "(1, 74, 7, 1536)\n",
            "inception_c\n",
            "(1, 74, 7, 1536)\n",
            "inception_c\n",
            "(1, 74, 7, 1536)\n",
            "max_pool\n",
            "(168, 1536)\n",
            "dropout\n",
            "(168, 1536)\n",
            "dense1\n",
            "(168, 1)\n",
            "dense2\n",
            "(1, 1)\n",
            "defined\n",
            "WARNING:tensorflow:From <ipython-input-12-52212b8b83f9>:98: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training accuracy 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vgwm22nDaDDx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InceptionModel():\n",
        "    '''\n",
        "    A base class for an Inception v4 model\n",
        "    '''\n",
        " \n",
        "    def __init__(self, input_shape, output_shape, ckpt_path='./', model_path='./'):\n",
        "        '''\n",
        "        Defines the input and output variables and stores the save locations of the model\n",
        "        Keyword arguments:\n",
        "        input_shape -- The shape of the input tensor, indexed by [sample, row, col, ch]\n",
        "        output_shape -- The shape of the output tensor, indexed by [sample, class]\n",
        "        ckpt_path -- The save path for checkpoints during training\n",
        "        model_path -- The save path for the forward propagation subgraph. The generated model\n",
        "                      can be used to classify images without allocating space for the gradients\n",
        "        '''\n",
        " \n",
        "        self.ckpt_path = ckpt_path\n",
        "        self.model_path = model_path\n",
        "        self.num_class = output_shape[1]\n",
        "        self.X = tf.placeholder(tf.float32, input_shape)\n",
        "        self.y = tf.placeholder(tf.float32, output_shape)\n",
        " \n",
        "        self.define_model()\n",
        "        print('defined')\n",
        "        return\n",
        " \n",
        "    def define_model(self):\n",
        "        '''\n",
        "        Defines the Inception v4 model.\n",
        "        '''\n",
        " \n",
        "        self.keep_prob = tf.placeholder(tf.float32)\n",
        " \n",
        "        with tf.variable_scope('input'):\n",
        "            _X = tf.image.resize_images(self.X, [86400, 7])\n",
        " \n",
        "        with tf.variable_scope('stem'):\n",
        "            _stem = stem(_X)\n",
        " \n",
        "        _inception_a = {-1: _stem}\n",
        "        for i in range(4):#4次运算，用字典来存放计算结果\n",
        "            with tf.variable_scope('inception_a_'+str(i)):\n",
        "                _inception_a[i] = inception_a(_inception_a[i-1])\n",
        " \n",
        "        with tf.variable_scope('reduction_a'):\n",
        "            _reduction_a = reduction_a(_inception_a[3])\n",
        "      \n",
        "        #another max_pool\n",
        "        _first_pool = tf.nn.max_pool([_reduction_a[0]], [1, 4, 1, 1], [1, 2, 1, 1], padding='VALID', name='pool')\n",
        " \n",
        "        _inception_b = {-1: _first_pool}\n",
        "        for i in range(7):\n",
        "            with tf.variable_scope('inception_b_'+str(i)):\n",
        "                _inception_b[i] = inception_b(_inception_b[i-1])\n",
        " \n",
        "        with tf.variable_scope('reduction_b'):\n",
        "            _reduction_b = reduction_b(_inception_b[6])\n",
        " \n",
        "        _inception_c = {-1: _reduction_b}\n",
        "        for i in range(3):\n",
        "            with tf.variable_scope('inception_c_'+str(i)):\n",
        "                _inception_c[i] = inception_c(_inception_c[i-1])\n",
        "        \n",
        "        pool = tf.nn.max_pool(_inception_c[2], [1, 4, 1, 1], [1, 3, 1, 1], padding='VALID', name='pool')\n",
        "        pool_f = tf.reshape(pool, [-1, 1536])\n",
        "        print(\"max_pool\")\n",
        "        print(pool_f.shape) # 168,1536\n",
        "        pool_drop = tf.nn.dropout(pool_f, self.keep_prob)\n",
        "        print(\"dropout\")\n",
        "        print(pool_drop.shape) # 168,1536\n",
        "        self.fc = dense(pool_drop, 'fc', 1)\n",
        "        print(\"dense1\")\n",
        "        print(self.fc.shape) #168, 1\n",
        "        self.y_hat=dense1(tf.reshape(self.fc,[1,-1]),'fc',1)\n",
        "        print(\"dense2\")\n",
        "        print(self.y_hat.shape)#1,1\n",
        "        #self.y_hat = tf.nn.softmax(self.fc, axis = 0, name='y_hat')\n",
        "        #print(\"softmax\")\n",
        "        #print(self.y_hat.shape)\n",
        "        # Creates a saver object exclusively for the forward propagation subgraph\n",
        "        model_variables = tf.get_collection_ref('tf.GraphKeys.MODEL_VARIABLES')\n",
        "        self.model_saver = tf.train.Saver(model_variables)\n",
        "        return\n",
        " \n",
        " \n",
        "    def train(self, data_generator, batch_size=1, epochs=4000, keep_prob=0.8):\n",
        "        '''\n",
        "        Defines the variables necessary for training then begins training\n",
        "        Keyword arguments:\n",
        "        data_generator -- a data_generator object with an implementation of get_batch, as seen\n",
        "                          in the data_generator.py module\n",
        "        batch_size -- the number of samples to be used in each training batch. Keep memory\n",
        "                      constraints in mind\n",
        "        epochs -- the number of epochs to be used for training\n",
        "        keep_prob -- the keep probability of the dropout layer to be used for training\n",
        "        '''\n",
        " \n",
        "        self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=self.y, logits=self.fc)\n",
        "        self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.cross_entropy)\n",
        " \n",
        "        self.correct_prediction = tf.equal(tf.argmax(self.y_hat, 1), tf.argmax(self.y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
        "        # Creates a saver object to generate checkpoints during training. This one also saves\n",
        "        # the gradients and the increment of the Adam Optimizer\n",
        "        self.saver = tf.train.Saver()\n",
        "        with tf.Session() as sess:\n",
        "            '''if os.path.isdir('train_model'): \n",
        "                self.saver.restore(sess, self.ckpt_path)\n",
        "            else:'''\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            for i in range(epochs):\n",
        "                images, labels = data_generator.get_batch(batch_size)\n",
        "                #print(images)\n",
        "                #print(labels)\n",
        "                if i % 50 == 0:\n",
        "                    train_accuracy = self.accuracy.eval(feed_dict={self.X: np.array(images).reshape(-1,n,7,1), self.y: np.array(labels).reshape(-1,1), self.keep_prob: keep_prob})\n",
        "                    print('step %d, training accuracy %g' % (i, train_accuracy))\n",
        "                    #print('step %d' % (i))\n",
        "                if i % 500 == 0:\n",
        "                    self.saver.save(sess, self.ckpt_path)\n",
        "                self.train_step.run(feed_dict={self.X: images, self.y: labels, self.keep_prob: keep_prob})\n",
        "                print('')\n",
        "            self.model_saver.save(sess, self.model_path)\n",
        " \n",
        "        return\n",
        " \n",
        " \n",
        "    def classify(self, image):\n",
        "        '''\n",
        "        Classifies the input image based on the trained model in model_path\n",
        "        Keyword arguments:\n",
        "        image -- the image, or image array, indexed by [sample, row, col, ch]\n",
        "        '''\n",
        " \n",
        "        with tf.Session() as sess:\n",
        "            self.model_saver.restore(sess, self.model_path)\n",
        " \n",
        "            y = self.y_hat.eval(feed_dict={self.X: image, self.keep_prob: 1.0})\n",
        " \n",
        "        return y\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gg-mxiFlaKSD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def stem(tensor):\n",
        "    '''\n",
        "    Generates the graph for the stem subgraph of the Inception v4 model\n",
        "    '''\n",
        " \n",
        "    conv_1     = conv(tensor,     'conv_1',     [3, 1, 1, 32],   [1, 2, 1, 1], padding='VALID')\n",
        " \n",
        "    conv_2     = conv(conv_1,     'conv_2',     [3, 1, 32, 32],  [1, 2, 1, 1], padding='VALID')\n",
        " \n",
        "    conv_3     = conv(conv_2,     'conv_3',     [3, 1, 32, 64],  [1, 2, 1, 1])\n",
        " \n",
        "    conv_4_1   = conv(conv_3,     'conv_4_1',   [3, 1, 64, 64],  [1, 2, 1, 1], padding='VALID')\n",
        "    conv_4_2   = conv(conv_3,     'conv_4_2',   [3, 1, 64, 96],  [1, 2, 1, 1], padding='VALID')\n",
        " \n",
        "    concat_1   = tf.concat([conv_4_1, conv_4_2], axis=3, name='concat_1')\n",
        " \n",
        "    conv_5_1_1 = conv(concat_1,   'conv_5_1_1', [1, 1, 160, 64], [1, 1, 1, 1])\n",
        "    conv_5_1_2 = conv(conv_5_1_1, 'conv_5_1_2', [3, 1, 64, 96],  [1, 2, 1, 1], padding='VALID')\n",
        " \n",
        "    conv_5_2_1 = conv(concat_1,   'conv_5_2_1', [1, 1, 160, 64], [1, 1, 1, 1])\n",
        "    #conv_5_2_2 = conv(conv_5_2_1, 'conv_5_2_2', [7, 1, 64, 64],  [1, 1, 1, 1])\n",
        "    #conv_5_2_3 = conv(conv_5_2_2, 'conv_5_2_3', [1, 7, 64, 64],  [1, 1, 1, 1])\n",
        "    conv_5_2_3 = conv(conv_5_2_1, 'conv_5_2_3', [1, 5, 64, 64],  [1, 1, 1, 1])\n",
        "    conv_5_2_4 = conv(conv_5_2_3, 'conv_5_2_4', [3, 1, 64, 96],  [1, 2, 1, 1], padding='VALID')\n",
        " \n",
        "    concat_2   = tf.concat([conv_5_1_2, conv_5_2_4], axis=3, name='concat_2')\n",
        " \n",
        "    conv_6_1   = conv(concat_2,   'conv_6_1_1', [3, 1, 192, 192],  [1, 2, 1, 1], padding='VALID')\n",
        "    pool_6_2   = tf.nn.max_pool(concat_2, [1, 3, 1, 1], [1, 2, 1, 1], padding='VALID', name='pool_6_2')\n",
        " \n",
        "    concat_3   = tf.concat([conv_6_1, pool_6_2], axis=3, name='concat_3')\n",
        "    print(\"stem\")\n",
        "    print(concat_3.shape)\n",
        " \n",
        "    return concat_3\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dT3Vb_laMb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inception_a(tensor):\n",
        "    '''\n",
        "    Generates the graph for the Inception A subgraph of the Inception v4 model\n",
        "    '''\n",
        " \n",
        "    pool_1_1 = tf.nn.avg_pool(tensor, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='pool_1_1')\n",
        "    conv_1_1 = conv(pool_1_1, 'conv_1_1', [1, 1, 384, 96], [1, 1, 1, 1])\n",
        " \n",
        "    conv_2_1 = conv(tensor,   'conv_2_1', [1, 1, 384, 96], [1, 1, 1, 1])\n",
        "    \n",
        "    conv_3_1 = conv(tensor,   'conv_3_1', [1, 1, 384, 64], [1, 1, 1, 1])\n",
        "    conv_3_2 = conv(conv_3_1, 'conv_3_2', [3, 1, 64, 96],  [1, 1, 1, 1])\n",
        " \n",
        "    conv_4_1 = conv(tensor,   'conv_4_1', [1, 1, 384, 64], [1, 1, 1, 1])\n",
        "    conv_4_2 = conv(conv_4_1, 'conv_4_2', [3, 1, 64, 96],  [1, 1, 1, 1])\n",
        "    conv_4_3 = conv(conv_4_2, 'conv_4_3', [3, 1, 96, 96],  [1, 1, 1, 1])\n",
        " \n",
        "    concat = tf.concat([conv_1_1, conv_2_1, conv_3_2, conv_4_3], axis=3, name='concat')\n",
        "    print(\"inception_a\")\n",
        "    print(concat.shape)\n",
        " \n",
        "    return concat\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9B02dfWAaOAA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reduction_a(tensor):\n",
        "    '''\n",
        "    Generates the graph for the Reduction A subgraph of the Inception v4 model\n",
        "    '''\n",
        " \n",
        "    pool_1_1 = tf.nn.max_pool(tensor, [1, 3, 1, 1], [1, 3, 1, 1], padding='VALID', name='pool_1_1')\n",
        " \n",
        "    conv_2_1 = conv(tensor,   'conv_2_1', [3, 1, 384, 384], [1, 3, 1, 1], padding='VALID')\n",
        " \n",
        "    conv_3_1 = conv(tensor,   'conv_3_1', [1, 1, 384, 192], [1, 1, 1, 1])\n",
        "    conv_3_2 = conv(conv_3_1, 'conv_3_2', [3, 1, 192, 224], [1, 1, 1, 1])\n",
        "    conv_3_3 = conv(conv_3_2, 'conv_3_3', [3, 1, 224, 256], [1, 3, 1, 1], padding='VALID')\n",
        " \n",
        "    concat = tf.concat([pool_1_1, conv_2_1, conv_3_3], axis=3, name='concat')\n",
        "    print(\"reduction_a\")\n",
        "    print(concat.shape)\n",
        " \n",
        "    return concat\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJfkaArOaPZH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inception_b(tensor):\n",
        "    '''\n",
        "    Generates the graph for the Inception B subgraph of the Inception v4 model\n",
        "    '''\n",
        " \n",
        "    pool_1_1 = tf.nn.avg_pool(tensor, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='pool_1_1')\n",
        "    conv_1_2 = conv(pool_1_1, 'conv_1_2', [1, 1, 1024, 128], [1, 1, 1, 1],)\n",
        " \n",
        "    conv_2_1 = conv(tensor,   'conv_2_1', [1, 1, 1024, 384], [1, 1, 1, 1])\n",
        " \n",
        "    conv_3_1 = conv(tensor,   'conv_3_1', [1, 1, 1024, 192], [1, 1, 1, 1])\n",
        "    conv_3_2 = conv(conv_3_1, 'conv_3_2', [1, 3, 192, 224],  [1, 1, 1, 1])\n",
        "    conv_3_3 = conv(conv_3_2, 'conv_3_3', [1, 3, 224, 256],  [1, 1, 1, 1])\n",
        " \n",
        "    conv_4_1 = conv(tensor,   'conv_4_1', [1, 1, 1024, 192], [1, 1, 1, 1])\n",
        "    conv_4_2 = conv(conv_4_1, 'conv_4_2', [1, 5, 192, 192],  [1, 1, 1, 1])\n",
        "    conv_4_3 = conv(conv_4_2, 'conv_4_3', [5, 1, 192, 224],  [1, 1, 1, 1])\n",
        "    conv_4_4 = conv(conv_4_3, 'conv_4_4', [1, 5, 224, 224],  [1, 1, 1, 1])\n",
        "    conv_4_5 = conv(conv_4_4, 'conv_4_5', [5, 1, 224, 256],  [1, 1, 1, 1])\n",
        " \n",
        "    concat = tf.concat([conv_1_2, conv_2_1, conv_3_3, conv_4_5], axis=3, name='concat')\n",
        "    print(\"inception_b\")\n",
        "    print(concat.shape)\n",
        " \n",
        "    return concat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHkoqQnUaQ7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reduction_b(tensor):\n",
        "    '''\n",
        "    Generates the graph for the Reduction B subgraph of the Inception v4 model\n",
        "    '''\n",
        " \n",
        "    pool_1_1 = tf.nn.max_pool(tensor, [1, 3, 1, 1], [1, 3, 1, 1], padding='VALID', name='pool_1_1')\n",
        " \n",
        "    conv_2_1 = conv(tensor,   'conv_2_1', [1, 1, 1024, 192], [1, 1, 1, 1])\n",
        "    conv_2_2 = conv(conv_2_1, 'conv_2_2', [3, 1, 192, 192],  [1, 3, 1, 1], padding='VALID')\n",
        " \n",
        "    conv_3_1 = conv(tensor,   'conv_3_1', [1, 1, 1024, 256], [1, 1, 1, 1])\n",
        "    conv_3_2 = conv(conv_3_1, 'conv_3_2', [1, 5, 256, 256],  [1, 1, 1, 1])\n",
        "    conv_3_3 = conv(conv_3_2, 'conv_3_3', [5, 1, 256, 320],  [1, 1, 1, 1])\n",
        "    conv_3_4 = conv(conv_3_3, 'conv_3_4', [3, 1, 320, 320],  [1, 3, 1, 1], padding='VALID')\n",
        " \n",
        "    concat = tf.concat([pool_1_1, conv_2_2, conv_3_4], axis=3, name='concat')\n",
        "    print(\"reduction_b\")\n",
        "    print(concat.shape)\n",
        " \n",
        "    return concat\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5Clvs71aSGf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inception_c(tensor):\n",
        "    '''\n",
        "    Generates the graph for the Inception C subgraph of the Inception v4 model\n",
        "    '''\n",
        " \n",
        "    pool_1_1   = tf.nn.avg_pool(tensor, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME', name='pool_1_1')\n",
        "    conv_1_2   = conv(pool_1_1, 'conv_1_2',   [1, 1, 1536, 256], [1, 1, 1, 1])\n",
        "    \n",
        "    conv_2_1   = conv(tensor,   'conv_2_1',   [1, 1, 1536, 256], [1, 1, 1, 1])\n",
        " \n",
        "    conv_3_1   = conv(tensor,   'conv_3_1',   [1, 1, 1536, 384], [1, 1, 1, 1])\n",
        "    conv_3_2_1 = conv(conv_3_1, 'conv_3_2_1', [1, 3, 384, 256],  [1, 1, 1, 1])\n",
        "    conv_3_2_2 = conv(conv_3_1, 'conv_3_2_2', [3, 1, 384, 256],  [1, 1, 1, 1])\n",
        " \n",
        "    conv_4_1   = conv(tensor,   'conv_4_1',   [1, 1, 1536, 384], [1, 1, 1, 1])\n",
        "    conv_4_2   = conv(conv_4_1, 'conv_4_2',   [1, 3, 384, 448],  [1, 1, 1, 1])\n",
        "    conv_4_3   = conv(conv_4_2, 'conv_4_3',   [3, 1, 448, 512],  [1, 1, 1, 1])\n",
        "    conv_4_3_1 = conv(conv_4_3, 'conv_4_3_1', [1, 3, 512, 256],  [1, 1, 1, 1])\n",
        "    conv_4_3_2 = conv(conv_4_3, 'conv_4_3_2', [3, 1, 512, 256],  [1, 1, 1, 1])\n",
        " \n",
        "    concat = tf.concat([conv_1_2, conv_2_1, conv_3_2_1, conv_3_2_2, conv_4_3_1, conv_4_3_2], axis=3, name='concat')\n",
        "    print(\"inception_c\")\n",
        "    print(concat.shape)\n",
        " \n",
        "    return concat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mF-Eg5unaT4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv(tensor, name, shape, strides=[1, 1, 1, 1], padding='SAME', activation=tf.nn.relu):\n",
        "    '''\n",
        "    Generates a convolutional layer\n",
        "    Keyword arguments:\n",
        "    tensor -- input tensor. Must be indexed by [sample, row, col, ch]\n",
        "    name -- the name that will be given to the tensorflow Variable in the GraphDef\n",
        "    shape -- the shape of the kernel. Must be indexed by [row, col, num_input_ch, num_output_ch]\n",
        "    strides -- the stride of the convolution. Must be indexed by [sample, row, col, ch]\n",
        "    padding -- if set to 'SAME', the output will have the same height and width as the input. If\n",
        "               set to 'VALID', the output will have its size reduced by the difference between the\n",
        "               tensor size and kernel size\n",
        "    activation -- the activation function to use\n",
        "    '''\n",
        " \n",
        "    W = tf.get_variable(name+\"_W\", shape)\n",
        "    b = tf.get_variable(name+\"_b\", shape[-1])\n",
        "    tf.add_to_collection('tf.GraphKeys.MODEL_VARIABLES', W)\n",
        "    tf.add_to_collection('tf.GraphKeys.MODEL_VARIABLES', b)\n",
        "    z = tf.nn.conv2d(tensor, W, strides=strides, padding=padding, name=name+'_z')\n",
        "    h = tf.add(z, b, name=name+'_h')\n",
        "    a = activation(h, name=name+'_a')\n",
        " \n",
        "    return a\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqZkEFqraVcJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dense(tensor, name, num_out):\n",
        "    '''\n",
        "    Generates a fully connected layer. Does not apply an activation function\n",
        "    Keyword arguments:\n",
        "    tensor -- input tensor. Must be indexed by [sample, ch]\n",
        "    name -- the name that will be given to the tensorflow Variable in the GraphDef\n",
        "    num_out -- the size of the output tensor\n",
        "    '''\n",
        " \n",
        "    W_fc = tf.get_variable('W_fc', [tensor.shape[1], num_out])\n",
        "    b_fc = tf.get_variable('b_fc', [num_out])\n",
        "    tf.add_to_collection('tf.GraphKeys.MODEL_VARIABLES', W_fc)\n",
        "    tf.add_to_collection('tf.GraphKeys.MODEL_VARIABLES', b_fc)\n",
        " \n",
        "    z_fc = tf.matmul(tensor, W_fc, name='z_fc')\n",
        "    h_fc = tf.add(z_fc, b_fc, name='h_fc')\n",
        " \n",
        "    return h_fc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_XapvxX1z3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dense1(tensor, name, num_out):\n",
        "    '''\n",
        "    Generates a fully connected layer. Does not apply an activation function\n",
        "    Keyword arguments:\n",
        "    tensor -- input tensor. Must be indexed by [sample, ch]\n",
        "    name -- the name that will be given to the tensorflow Variable in the GraphDef\n",
        "    num_out -- the size of the output tensor\n",
        "    '''\n",
        " \n",
        "    W_fc = tf.get_variable('W_fc1', [tensor.shape[1], num_out])\n",
        "    b_fc = tf.get_variable('b_fc1', [num_out])\n",
        "    tf.add_to_collection('tf.GraphKeys.MODEL_VARIABLES', W_fc)\n",
        "    tf.add_to_collection('tf.GraphKeys.MODEL_VARIABLES', b_fc)\n",
        " \n",
        "    z_fc = tf.matmul(tensor, W_fc, name='z_fc1')\n",
        "    h_fc = tf.add(z_fc, b_fc, name='h_fc1')\n",
        " \n",
        "    return h_fc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wQunWv4yeDCk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "zBA_g1Du_8G9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9dtdHuPUcWIS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jxXO97jm_jKX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcFErvdoAqIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "filters: \n",
        "Integer, the dimensionality of the output space (i.e. the number of \n",
        "output filters in the convolution).\n",
        "\n",
        "kernel_size: \n",
        "An integer or tuple/list of a single integer, specifying the length\n",
        "of the 1D convolution window.An integer or tuple/list of 2 integers, specifying \n",
        "the height and width of the 2D convolution window. Can be a single integer to\n",
        "specify the same value for all spatial dimensions.\n",
        "\n",
        "strides: \n",
        "An integer or tuple/list of a single integer, specifying the stride \n",
        "length of the convolution. Specifying any stride value != 1 is incompatible with\n",
        "specifying any dilation_rate value != 1.\n",
        "'''\n",
        "c = {'filters':[32,32,64,64],\n",
        "     'kernel_size':[[3,1],[1,3],[5,5],[5,5]],\n",
        "     'strides':[[2,1],[1,2],[3,3],[3,3]]}\n",
        "\n",
        "\n",
        "'''\n",
        "pool_size: \n",
        "Integer, size of the max pooling windows.\n",
        "'''\n",
        "\n",
        "p = {'pool_size':[2,2,3,3]}\n",
        "\n",
        "'''\n",
        "rate: \n",
        "float between 0 and 1. Fraction of the input units to drop.\n",
        "'''\n",
        "d = {'rate':[.7, .7]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihHc9fHE_oO3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  # Conv + MaxPooling\n",
        "  model.add(Conv2D(filters=c['filters'][0], kernel_size=c['kernel_size'][0], strides=c['strides'][0], input_shape=(60*24, 7, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "  model.add(Conv2D(filters=c['filters'][1], kernel_size=c['kernel_size'][1], strides=c['strides'][1], padding='SAME'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "  model.add(Conv2D(filters=c['filters'][2], kernel_size=c['kernel_size'][2], strides=c['strides'][2], padding='SAME'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "  model.add(Conv2D(filters=c['filters'][3], kernel_size=c['kernel_size'][3], strides=c['strides'][3], padding='SAME'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "\n",
        "  # Dense\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(d['rate'][0], noise_shape=None, seed=None))\n",
        "  model.add(Dense(units=64, activation='relu', input_dim=100))\n",
        "  model.add(Dropout(d['rate'][1], noise_shape=None, seed=None))\n",
        "  model.add(Dense(units=1, activation='relu', input_dim=64))\n",
        "\n",
        "  model.compile(loss=losses.mean_squared_error,\n",
        "                optimizer='Adam',\n",
        "                metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3i7OSuhb_uwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m2 = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q48mSDTNK4qm",
        "colab_type": "code",
        "outputId": "b725db24-f19b-42d6-e84a-7a6d776176a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "cell_type": "code",
      "source": [
        "m2.fit(X[:200], y[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-56db9bd7e1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    291\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 200 arrays: [array([[ 609.87      ],\n       [ 609.87      ],\n       [ 609.41      ],\n       ...,\n       [   2.46080742],\n       [1501.5275298 ],\n       [ 610.1767727 ]]), array([[6.09870000e+02],\n       [6.098700..."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wQG3mvkvH6Up",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.assert_input_compatibility(xs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "92GGpBISH_27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = np.array(X[:200]), np.array(y[:200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pX-BzW_OKb0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs = np.array(list(map(lambda x:tf.stack(x), x_batch)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDvPlNJ6LTsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ys = np.array(list(map(lambda x:tf.stack(x), y_batch)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a394ITn_LbM4",
        "colab_type": "code",
        "outputId": "92e67e07-4ac9-4997-d3b4-c6da2cf1d52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.stack(X[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'stack_1:0' shape=(200, 10080) dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "DY2NPij2T62G",
        "colab_type": "code",
        "outputId": "5996ae32-1af4-47b1-e6cf-b36a2d5f49b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(y), len(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(902977, 902977)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "HaNtBcESJwxC",
        "colab_type": "code",
        "outputId": "ee299ad8-cdab-45e0-82c3-a5e400ed8b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.stack(x_batch[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'stack_1:0' shape=(86400, 7, 1) dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "Weu7Fw5WS2rJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs = tf.reshape(tf.stack(X[:200]), (200,60*24,7,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3GqjsnVgTUCK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ys = tf.reshape(tf.stack(y[:200]), (200, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFp0u8MsWYlq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1lNqIIydHZ0S",
        "colab_type": "code",
        "outputId": "5595fa6f-5bda-4c47-ac3e-29d7ca119c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "for i in trange(0,len(X)//16,200):\n",
        "  xs = tf.reshape(tf.stack(X[i:i+200]), (200,60*24,7,1))\n",
        "  ys = tf.reshape(tf.stack(y[i:i+200]), (200, 1))\n",
        "  model.train_on_batch(xs, ys)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [13:37<00:00,  4.26s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hlSS6jjil5LV",
        "colab_type": "code",
        "outputId": "798385b6-6f1a-4a6e-d466-80d802839080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Network.add_loss of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4f3ef40ac8>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "TFMieSHgigIh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PmTwOGEEiiky",
        "colab_type": "code",
        "outputId": "540801d5-1e2a-4102-8065-51dc7428df1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "cell_type": "code",
      "source": [
        "with open('model', 'wb') as f:\n",
        "  pickle.dump(model, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6a7e1380eaa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__reduce__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mResourceVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscatter_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    685\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     raise NotImplementedError(\n\u001b[0;32m--> 687\u001b[0;31m         \"numpy() is only available when eager execution is enabled.\")\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcount_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: numpy() is only available when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dzc7Krqml19y",
        "colab_type": "code",
        "outputId": "007c514f-e500-4b3f-bff6-47e3b0fca6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ddf3115bdcc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5421\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5422\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5423\u001b[0;31m         server_def=None)\n\u001b[0m\u001b[1;32m   5424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   5465\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5466\u001b[0m       raise ValueError(\n\u001b[0;32m-> 5467\u001b[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5468\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5469\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Fs5E_r3AG3U1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RiqOjLPONu38",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "price = np.array(bitstamp[130000:200030])[:,1]\n",
        "def eval(price):\n",
        "  count = 0;\n",
        "  for i in range(29):\n",
        "    if (price[i + 1] > price[i]):\n",
        "      count = count + 1;\n",
        "  return count / 30\n",
        "  #print(count)\n",
        "  #print(count / 1440)\n",
        "  #if (count > 720):\n",
        "    #return count / 1440\n",
        "  #else:\n",
        "    #return - (1440 - count) / 1440"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RqSjbi8wq9Hd",
        "colab_type": "code",
        "outputId": "20a88176-7a85-4537-ca51-d44cc7a5bb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(result, label='our model')\n",
        "plt.plot(bitcoin, label='reality')\n",
        "plt.legend()\n",
        "plt.xlabel('time / minute')\n",
        "plt.ylabel('currency / USD')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'currency / USD')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsnXd8FGX6wL+b3gshIRAg9Jcq0kE6\n2OvZuz97ORtY8Tz1bCf2U8F2iuXuVDy7nmKhg1JVkPbSS2hJIL1nd39/zPad2ewm2c0mvN/PB515\n552ZZ5dlnnmfarJarSgUCoVC4S8RLS2AQqFQKFoXSnEoFAqFIiCU4lAoFApFQCjFoVAoFIqAUIpD\noVAoFAER1dICBJuCgrImhY2lpydQVFTZXOIEldYkK7QueZWswaM1yduaZIWmyZuZmWwyOqZWHA0Q\nFRXZ0iL4TWuSFVqXvErW4NGa5G1NskLw5FWKQ6FQKBQBoRSHQqFQKAJCKQ6FQqFQBIRSHAqFQqEI\nCKU4FAqFQhEQSnEoFAqFIiCU4lAoFApFQCjFoVAoFG2IerOFg0cquPXFxZSU1wTlHm0+c1yhUCiO\nJW58dpFj+4pH5jFnxpRmv4dacSgUCkUbwWyxhOQ+SnEoFApFG+HTRTtDcp+gmqqEEAOBL4EXpZSz\nbGN3AM8D6VLKctvY5cA0wAK8KaV8WwgRDbwL5AJm4Bop5U4hxGDgNcAKrJdS3hLMz6BQKBSthU17\njrrt9+qSFpT7BG3FIYRIBF4B5ruMXQV0AA54zHsYOBGYBEwXQrQDLgOKpZTjgCeBp2yn/AO4U0o5\nFkgVQpwWrM+gUCgUrYmUxBi3/UtO7BOU+wTTVFUDnI6LkgA+l1I+iLZasDMKWC2lLJFSVgHLgbHA\nVOBz25yfgLFCiBigu5RytW38azSFo1AoFMc8g3u2d9uPjAzOIz5opiopZT1QL4RwHSvTmZoNFLjs\n5wMdXcellBYhhNU2VqQz15D09IQmlxbOzExu0vmhpDXJCq1LXiVr8GhN8oazrL1y27ntD+iRQXxs\n8z/mwzEc16h5iN64YaMRO01tupKZmUxBgZ6+Cz9ak6zQuuRVsgaP1iRvuMu6d3+x2358bFSj5fWl\nIMMhquoA2krCTo5tzDFuc5SbgINAhs5chUKhOOZ557stIblPOCiOlcAIIUSaECIJzb+xFPgBuNA2\n5yxgoZSyDtgihBhnGz8PmBdqgRUKhSLceeOeSUG7dtBMVUKIYWhht92AOiHEBcCPwEloK4nvhBC/\nSCnvE0LMAL5Hc5o/KqUsEULMBU4SQixDc7Rfbbv0NOANIUQEsFJK+VOwPoNCoVC0Ft76ZpNje2CP\ndkRHBW9dEEzn+Fq08FpPntSZ+wnwiceYGbhGZ+4mYHzzSOk/VqsVk6lBl4pCoVC0CD9vOOTYPm1U\nblDvFQ6mqrCnzlLPbQvv54Mtn7a0KAqFQtEg6cmxQb2+Uhx+UFpTCsDyAysBbfWxKG85eWXKL69Q\nKFqW6tp6vl6+y20su11CUO+pFIcfRJjcv6aNR7bw361f8sKvr7aQRAqFQqHxv1/28PnSXQ1PbEaU\n4vADT99GeV0FADXm2pYQR6FQKBwcKakO+T2V4vAD1xXHNzu/x2q1+pitUCgUocPSAs8jpTj8YM2h\n3xzb3+2eT52lvgWlUSgUCidxMe7BsZERwY/+VIrDD/aW7XfbN1vNLSSJQnFsUVcfmsZErRmLxX3F\nEczEPzvhWKsq7IiOiHbb/2TbVy0kiUJx7HC4qJIH3lgBEJT2p20Fz/SyCLXiCA8iI5pWXVehUATO\nyo2HHdvVtco8bESPTimO7QHd0kNyT6U4/CDSpL4mhSJYlFXW8vh7a/hx9T638a9/3u3YVvEoxti/\nmktP7M3dlwxxjFuswTPzqSeiH2TEhUaLKxTHIpc99B27Dpby4fxt7DnkLAFudrHd3/riEqpq1KpD\nD6vte0pJ0Lr/mS1mftyziNsXzmD53tW+Tm00SnH4QYfErJYWQaE4Jiit1HKjPB2+oCmPtkZ5VR2r\nNh9m+R8HMVsat0Kwf1V238Ydix7gix3fAvDSL3OaRU5PlHPcD1TehkIRHLbsKXLbz0iJAyC/uKol\nxAk5f3lzBeVVdQCs2ZLP4aIqHrtuJFEBtHy153GYCN2zSq04FApFi7Hod/dQd6vVyu5DpfzlzRUt\nJFFosSsNgHU7jnDoaCU3PruowfOqa+sdKxR75ni92cL/dv0YFDk9USsOhULRYniapKxWeOzdNS0k\nTfBZuu4A73y3haduHE11rXE+2N7DZXTtoN+61Wq18ucXvM12xeW1LCxc5jY2pOPApglsgFpx+IEV\n4+WfMmMpFI0nNto91P23bQWGc/uHKNQ0mNhbuz7w5goefdfYcf23d1az/I+DXDtzAR/N3+Z2bNZn\nfxie1z21q9v+DcMubYK0xgR1xSGEGAh8CbwopZwlhOgC/AuIROsffqWUskYIUQcsdzl1KppSexfI\nBczANVLKnUKIwcBraFFo66WUtwTzM4Bv5bC+cBODMwcEWwSFos2w93AZf3tnNXdecBzJtkggO76q\nvB5r72hv/28zAD+s3sclU3s7xn/bVqg7v6qmnv4d+7D56FbH2JGqItrR/ME9QVtxCCESgVeA+S7D\njwGzpZTjge3AtbbxEinlJJc/ZuAyoFhKOQ6ta+BTtrn/AO6UUo4FUoUQpwXrM9jxteLYdFQG+/YK\nRZviuY9+B+ClT9Yzb9VeABLjGn6HVat735wxJpeshEy3sS4pnYJyr2CaqmqA0wHXbkeTAHu9jq+B\nE32cPxX43Lb9EzBWCBEDdJdS2td4DV2jWfBVfbKmXpVWVygCQS8fo0tWUoPn6UToHjN8tmQHny7e\nwY+r9zGyn/sKYuzAbG48qz8x0ZEcrS52O5YQEx8UeYLZc7weqBdCuA4nSilrbNv5QEfbdpwQ4gM0\ns9SnUsoXgGygwHYtixDCahtzjd9zvYYu6ekJREU1rWTI/po8w2PWKDOZmfpOrJYgnGTxh9Ykr5K1\neTDraIAu2Sls2VtMt44p7D5YqnteVFREWHyu5pbh77eM5fDRCl6a+7vhnG9+3mN47P6rRzp6Bs1d\n8LnX8WB8Zy0ZVeVaiese4N9ofoslQgi9TB+9yl0NVvMqKqpsnHQ2qmPK+G7bQsPja/avo6CgzPB4\nKMnMTA4bWfyhNcmrZG0eXvx4ndfY4N7tibT9S7Yrjb/fOJoDhRWkJ8fywtzfqaiup7bW3OKfKxjf\nbXp8FB26pfP0zWM4fLSSF3S+IyPOGdedwsJyQMsY16Ox8vpSOKGOqioXQtjXTjnYzFhSytellOVS\nygo0n8gg27FsACFENJqSOAhkuFzPcY1gcbhc3xGlUByLWCzWJvka/th5xGvs3Em9vMZSEqIZ2ieT\n7h1TeGXaBKIiTW3Kx/H4dSO5YFJPhvRuT2xMJCaTicy0eDJS4/y+xhUn9+Gccd0d+3csesCxHWGK\n4LkJjzWrzK6EWnH8BJxv2z4fmCc0PhBCmIQQUcBYYCPwA3Chbe5ZwEIpZR2wRQgxzjZ+HjAvmAJX\n1h0bGawKhT/c9Nwih3O7uRjWt4OX6cCzOZHJZGqRTnfNyetfbnBsd2yfyOmjc7n9/OPc5nTMSCQh\n1j9D0PjjjB3fdxx/A/FR/iuhQAmaqUoIMQx4HugG1AkhLgAuB94VQtwE7AHek1LWCSH2AasAC/CV\nlHKVEGItcJIQYhmao/1q26WnAW8IISKAlVLKn4L1GQBKa3wv85JjGnbqKRRtBbPFymaPMiH+4rli\nePv+yQ7b/NGyGrdjnj0lIkymVu8cX7U537Ed4dlEw4UXbx/HvJV76JKVzMufrjecFx3lfO8vr6tw\nO9Yurl0TJG2YYDrH16JFUXlyks7c+3XGzMA1OuObgPHNIKJfvP/7pz6P5yT69M0rFG2GppqKqmqc\nNvgXbxvrUBoAKzcd1jvFgcnU+sJxSypqqa6tp0N6QkDnRUdFcNbY7j7nuEZWrS/YyBt/vOd2PCM+\nuMmSquRIE8lN6dLSIigUIcHVVFRXb3F74/UHude5UklNijWc1y/X+6FXXWtm7+HygO7X0kx/RSv/\nMWfGFGrrGtduenDPDNbtOMKt5w5kmMhi54FSPpy/lZvOdiYd/16wwccVgoNSHI0gN6ULe0q1pjNp\nsaktLI1CERpcX/hvem4R0y8azKAeGcYnePCKj1IZrvTMSWl4Upjjujq6duaCRl/npnMGsGN/qaPc\nSo9OKTx45XC3OTXmGr1Tg4qqVdUILux9tmPbV1a5QtGW8CxIqBda60qNjyJ+vjhtVG6jzgsndhzQ\nz0UJlLiYKAZ0b+dm1vMkISo4SX6+UIojAIZ3OJ5r+l9KhEsr2WC2Z1QowolCW/luV2rrzNTomGFW\nbjrMLS8sZsWmQwHfJ97PqKJw5o8d3mHHwcNdqVwz4LKg31EpjgC4ZsBlDM8e4qb91YpDcaxQVO5t\nErn5+cXc8vxir/E3vtoIwJtfbfI6NuPyoc0vXJjh2i/dk/Mn9mjWe9Va3MseDe9wfLNeX4/Wr9pb\nAJOLhm9tkR4KRWNJ8+HQLiiuIjNN32RSVFbDw2+vdOznZhtnJJ80XD/YJD051mcIa2vh0qm9mTqs\nc7Ne07OwYShQiqMRuCoOZapSHCvo9QG3U1tv/O/g7tnL3fY9e3AAPHDFUL79ZQ9/Gu8MQ62ur+Hu\nJQ+RndiBCNNowl1vbNp9lLz8cvIKKnSPZ6XFc9KI5o/CTItxBhO8Mnlms19fD6U4GkFkhPOHr0xV\niraA2WJhwdr9jBrQgRSPHhmuc4x4/YsNPH79KAAqq+sM5xnRu3Mad16Y5ja27IDWPvZQxWHiTWZM\nYf648pVR75rs2NxY0P5ePP2vwUT5OBqB61+/MlUp2gLTX1nOh/O38dd/Ok1KFquVXQdLHfkbZrP2\n/9NGdWXOjCm8fKczD3d/ofMt295jQ497L/G2v5fWlPPC2lf5Nd89S1oe3e7cMVlaZSOn3OxkBvYw\njoqyWq3UWeqprm98SK3978cUIqUBasXhE6Nqk7iZqlrhr1mh8KC8qs7x/zVb8hneN4u7XllGaaU2\nPmfGFCptfTQibaVsk+Kj3a5htVopr6ozLAGeEBtFX53kvuu/uBeAHSW76TByOjlJWjUG1yZplrgS\nIitDb8tvKtMuHExqov4KDuD9zXNZdehXAK7sdxFZCZn0SA0sHNluLg/VagOU4vBJWZ1+pmpZpTOK\nwYrycShaNzs9cg5e/WIDp47s6lAaduyvS+WV+qao6542bj+QFB/ttkIxoqi62KE4XKnpupzI4lzg\nhAavEU54Kg2L1UJxTQnt4jQFalcaAP/a/DEAWQnteWT0fT6va7FaMGHCZDI56lSF0myuFIcPymqd\ny+8ZI6Y5trfsdXbZUqYqRWvniffXeI15mpuunbmA9raS39kZiY7xq04VvD9Pv33y5Sf14cCRCgZ0\na8eQ3u115+wvP+i2nxGvFecrrPLOgzCnGTczcqXebKGqpt6rn3k4MGPZY1TUVXJerzMZ1L6f7pz8\nykKKa0p8VqW4feEM3fNChfJx+KDOor1ZDcsaTJdkZwljV11hUc5xRSumtNL/1sf2BMCCYmergYmD\njUt7Tzy+E1eeLBjaJ9PQxv/9bu9yHJuPbOWRX572Wy5PnnhvDXe+vIyt+4pZsu4A185cwObdRxt1\nrVueX8y1Mxc06gXxzXsneY1V1GmN5T7b/g2PrnjW8NwHlz/JhsLN3LrgPpbk/ex27P1Nc3XPCWYZ\ndU+U4vBBcU0J4PzLtlPtUuVTrTgUrZlpLy8L+JwRfZ2VWY0Uwtv3TyYqsuHHi6d5xWK1MGvdWwHL\n5MrefM3EPPM/v/Lud1sAeLaRPUTsWfG+zHB6zJo2wa/P74vX1r8DwNytX7iNrzy0Vne+/XkVCpTi\n8MEB2zJ6UGZ/x1htnZl5y5x19VU4ruJYo0enhosQNhR6an/h8nTo7i4xjsgyVQW3VHhT+ODHrY7t\nOTOmkBAXei/Aad1ODNm9lI/DB9/tng/A1qIdTOo8FtBKLEAk1RtHEzdghUoAVLRaXMuc+8vt5w9q\n8pv0zpLdPL/2Va7oeyExEe6RWR9I4/43Jot34qAeHdolcPhopdf4gcIKOrVP1DnDP1yr3M6ePoGd\nB0t5vpm7IRrxydavwAQp0ckM73A8aw477zuu0yj6pPckJjLaxxWal6AqDiHEQOBL4EUp5SwhRBfg\nX0AkWv/wK6WUNUKIy9E6+1mAN6WUb9v6jL8L5AJm4Bop5U4hxGDgNcAKrJdS3hLMzwCeJcTcR9WK\nQ9FaefqD3wyPJcRGcdrorny6eKfb+JDe3iGxZ53Qza0209v3T/Z535d+exOAf2/5r2MsOiLa4VNs\nDFarlZKKWtKSYok2UGx/fWslj183kte/3MjNfxpIThOUyK0vLmn0uZ5MH3oLxdXFvLPpQ8M5C/OM\nTYqXiPOCllxoRNBMVUKIROAVYL7L8GPAbCnleGA7cK1t3sPAiWgdA6cLIdoBlwHFUspxwJPAU7Zr\n/AO4U0o5FkgVQpwWrM9gpwtD+XHNPt26+vVmteJQtH7OHtvNbX/qsM6cMaabWwjtgO767UjPneBe\ntK+hh1hStPcDu5s/DdFMxi9pH/y4jbtmLeetbzaRV2Dc8OnRd1ezv7CC92y+D4CNu46ydV+x7nzP\nXJWGeOj/hjc8yYPclC4Mzx7CzHEPc9vg6wM694q+F4ZcaUBwVxw1wOmAa1vYScDNtu2vgXsACayW\nUpYACCGWA2OBqcD7trk/AXOEEDFAdynlapdrnAh819zCf7/L6Qz7+H/5QL77BNtveOeBUhDNfXeF\nIrR0zHB/mKcmaaGsSfHRvHHPJFZsOqS72rAzZ8YUv7sC6jlxOyZms614J6kxyZTUlume52t1P//X\nPAB+3uC7jHu9LfvdnsyYl1/O83M1s8+My4fSp4t72RNzAI3On/vzCbRLMY5sqnQJsnly7IPsKN5F\nXvlBoiO0x3ByTFJABQuv6HshYzqN8Ht+cxLMnuP1QL0Qbk/VRCmlPbc+H+gIZAMFLnO8xqWUFiGE\n1TZWpDPXkPT0BKKi/LONuvL1gnmO7T9N7EnnrGRm/dfbnllYUk1mpnG1z1ATTrL4Q2uSty3J6hoN\nmJOZRJJH5dtTTuhBWrJz7LyOzdPp8qK53pblP/U7xeErtCuNp06awcZ8SVJMEq+v/heg9R1vzN9B\nTmYi+z0KDx4orGBXQQWPz1nlGJv5n1/5+vlzHPt19Vo+SEN8+ezZREQ0/NZ/6cfO3IteOTn07uxd\nJTeTZIbtGcTaAw13SzzzuEl+ZYsH43fbks5xo286kPEG/7aKirydZP4QFxVLVb0Wt372GK0EwJwZ\nUwBYt72Ql79dCkBpRS0FBfpvSKEmMzM5bGTxh9Ykb1uStabO7NZD47FrR3i9qZeWVFJX7Z3jUVh1\nhLjIOJJiGu8f8GRc1xHM27zUbcxUFcOYjDEAPD3uEe5b8hj1ZnPAfwdThuZwxclC18z8uEupdzsF\nBWVsyysmKT6aB//pfnzahcfx8cIdXDCpJy9/otXVuvfSIRw54l8vdLNLIE1hofE514grOKXzIdJj\n07h36SOG844U6lfhdaUpv1tfCifUiqNcCBEvpawCcoADtj/ZLnNygBUu4+tsjnITmkM9w2PugWAI\nemb3U/jvti91j8W4lIWOi1ERzYrWhd00Y0fPRh4Trf+7tifmzZ7yTLPIcl6vM+maluPWqgDck9k0\nJaUdLymvIdVHXxBPLpjUE4BzxnXny2W7fM7tmZPCDc8sNDRPHdezPVNHd3d7EPfTqb1lZ0nezxRU\nHeH83mf5LS9ofx+eZVcy4tphsVooqtF8MZeI8wK6ZnMTasXxE3A+8G/b/+cBK4G3hBBpQD2af2Ma\nkAJcCHwPnAUslFLWCSG2CCHGSSmXAeehOeCbnUldxvJ7wR+c1neS17FIl2Vp56zWY75QKAC253n7\nGIb3zeKXjYeYOrQzPTunEhnR/C9EnsmyrsrHbHUvKBoV4fFosprAZMVfl8OcGVOwWK2O5k9nj+3W\noOLYsd//PuG3nzeIFB/FC8GZuDe16wR2lvhXLsWTc3udwefb/8dNx/0fOUkdqaqvRh7dxvFZgxp1\nveYiaIpDCDEMeB7oBtQJIS4ALgfeFULcBOwB3rMpgxloCsIKPCqlLBFCzAVOEkIsQ3O0X2279DTg\nDSFEBLBSSvlTsD7DtKE36y71NMWh/SCjIsO8u4xCYeOWFxZTU+v+gL7r4sGA1lzpnkuG+Dy/qVUS\nXIuGvjzpKbdjC/Yt9ZzujcnKfxdu58azB/h1P9eOga6rqsgIk9uqomenFHYc8F9pAAzp49uJXVbr\n/KwPLn8yoGu7cmLXiUzuPM7RAyg+Kq7FlQYE1zm+Fi2KypOTdOZ+AnziMWYGrtGZuwlouMxmEHF1\nhPnqiqZQhAv5RZVeSgNgYPcMndn6uCa7ltaWkRIT2Gr7Y+ksneHaDM0fTJFmTAllrFh1mBWbDtOj\nUwp3XTSYhDj/w2WfuWUMViu0S4nl1c838Ns2rSjgTWcP4L7XfzE8b2CPdkwZGli713UFGwKa74tA\nv6tQoAz0jcDVVKVqVSlaA39509sRHCiuBT0fWPY4H2wxzvLW47eChiOFACbkNFw6feeBUm77x1Kt\nEZJH29qLp/TSPad9ajyZafFERkRw5gndADh9dK5uiI1rXsulU3tzfC/96r5GfCg/MzzWK6274bHW\ngl+KQwiRaUvKU+CuOFQjJ0VrQO93+szNYwK6htWjvM7yA8bKqN5Sz+/5f1BnDjwbfKBBuXE9zBYr\nsz5zKqQ5M6ZwysiuDZ7XvWMKc2ZM4YJJPb38OZdO7c2fxjuTGuNimtcwc0Xfi5r1ei2Bz29ECHEn\nMMM2L0kIcQh4Qkr5diiEC1ciIkyOBEClOBStkdvOG0T7tPiAzvHsnQEwc/VLnNn9ZK+H/QdbPmXl\nobWM6DCEqwdc6nasa3KOz/sMyPA/o7au3sIfO717dwSCawrG3Rcf75UhbxRh5sne0jyKakqoqDMO\nk3150lNhaXoKFEPFIYS4HrgAGC+l3C6EMAEjgFeEECYpZdNqH7diXB1tdr1htVqxYg1p+0aFwhdW\nq9WwHMWgHoEbEMw6BT33le3ntfXv8MrkmW6/fXvp79WHf+PqAZdSb3Em0l3d/1Kv6zSWumYo+ePq\ns3RVGn+7ZgT7CytI9NOP8vSalw2P3TPsVroH2BI2nPG14rgCuEBKeRhASmkFVgkhzkYr8XHsKg6X\n/9rLIDy7ZhaF1Ud4ZvzfWkoshQKAyuo6yiprufPlZfTvls4lU3t7zYluRDWFhCjjFcrBisO6LV8B\nPtv2DfP3OYsCZiYE5i8AsNTEoeeMeP2LpjuhjbK+u3ZIpmuH5gm3b0tKAxowVdmVhueYEKI6eCKF\nP5lp8cTHRmoqwwo/7lnEnrJ9LS2WQkG92cLFD37r2N+0u4iH33aW1ThhYDbnT+zZqGvrrTjsVNfX\nGB5zVRrg3YMDYFD7/vxRuInbjg+syJ9rG+fGEhHEIoEPj7qHlNi2l+vly67iaw14TCuOiAgTV5/a\nF9BWHN/s+qGFJVIoNFzbuupx/Zn9SU/2zrzeeGQLty64j7WHjftLWFyS9G4//ga3Yy/8+qpjuzHJ\nbtcOuJx7ht1Gv3Z9fMzy7U+8/kz/nequRPpRZ6qxdEjMIt7HSq214mvF0V8I8b7OuAlo3N9QG0Xl\ncijChdo64/e9XB9ml1fXzQFgzsYP6JaSS0Z8uqPh0vUDr2RI1iDqLZriODl3Mn3b9Wb2lGe4dcF9\nXtd6fu1sw/s8O/5R3fGYyGi6pzYcDeWL4UJrabu1aAeL8pZz/cAriDBFUFh1lHZxaYb+R19lyctr\nKyitLaNTUrbhnGMRX4rjfh/Hgpat3Vqw/9isgNkMJpvJuM5cR3QIO3EpFK48+u5qw2MPXa3fK8Iz\nF+nhX57ipK6T+HHvIgDe2vAvZk95hsp6rWBodb2+wWFJ3i8cqvSybjt4cuyDJEQH7+3bXtL9pd/e\nAOC9TR+x9vA6rFiZ0mW8Yc2oSFv1h44ZCV7H7l+mKbq/jb6fzAT/kyUBXpzY+IzxcMdQcUgp33Pd\nt0VVDQbypJSFwRas1eCx2NhTVECv9p1aRhaFwgdGtvzPt//Pa8yuNOz8b+cPJNoq4rpmjPdM7c6O\nEq0G1Nytn7ud49pb4y8jp5MW2zyl2Y3wXDm4tlddsG+poeKIMJmYPX2Cz7Dbv614OqDCjs9NeCyk\nrVxDja9w3MloORtjbUpjMdAFiBZCXC+lnGd07rGA80dqxVV7RKk27opWhqfzWo9vdzuNDK4FCW87\n/nqmL35Q95wHRk4nOSap6QI2EzXmWmIj9QsTxsc27t9tdX010RHR3LHoAcdYc1UODmd8fVt/B261\nbZ8KtAN6A5nAXLTKtscsru82pkinXTmQjmEKRXPiq/zN0wZZ4nvL8gK+j+uKw+it+s4hNzWz0jDh\nyznep0sK+ZUFZCVk0iU5h31l+73mbCjcxHHtB7ClaBv92vXxrsDbAK7+nLuG/pmvd85jW/FOH2e0\nXXxFVdVIKX+1bZ8OfCylrJdSHgS8O7wcYzh9HO4/5mV/HKS43Dg0UaEIBr9tK+C6p53tjs8Y48wb\nmD19ApkGWeJPrzZOWjNiVMeG+2r3SW9cyG9j6Tx0F4+ueJZNR6Su0gDN8f/R1s95ff27vL3hP026\n3wu/vnrMKg3wvzruFJy9wgHarvGuiSxZt5/tu2t4/LpRLS2K4hihqKyGVz51LyB4/sSeDBdZVFTX\nNdoMo0dOUkdDc09L0adLGr8c1Awgs9f5roa04uAaANYXbgS0mlp3LvoLgFf2O2hJj5X1vkOcXWnL\nDnFXfK048oUQdwohHgISgWUAQogJqBWHY8Xh2cvYaEyhCBbvfLtZdzw3O5n+3YxLizTGTPWXkdO9\nxjyrvT49zrjdaaPxsFIlxTvfXRubh1FrruWp1S859v+6/O9ec+os/hVpHJjRj9lTnmnTDnFXfCmO\nPwMD0CKpzpFSWoUQ8cC/gHtCIVw4Y/xTVT4ORWgpLm/ce5wvM9UJHUcye8ozzBgxzTHWxaA44fSh\nt7jtN2c/ciOG981ybN94Vn9I1fNkAAAgAElEQVSfc41yR6Yv/iuHKpzhwyW17s2cftq7mDqXGltG\nzJ7yDLcM9mod1KbxFY5bCNzoMVYlhOgupWxUZTFb177XgYFoq5ab0arvDgPsJS6flVL+TwhxOVq3\nPwvwppTybVvv8XeBXMAMXCOlbBFDoyOqylODqIaAihCTV1De8KQG6J3Ww81mb3/4d0nuxKNj7mfZ\n/pVM6Gxchn3W5Kc5XJlPh4QswznNyWUn9mbRb5ovw1cP8sfGzCAhOp602FSKa7xb5rqSldCelQfX\n8v7mubrHZ095hsTUKAoKy7h3qbaqOlZMU574Csd92GPICpQAXwB7G3m/c4BUKeUJQoiewEtAIfCA\nlPIbl3snAg8DI9EUzGohxOdovceLpZSXCyFOBp4CLm6kLE0iiOVtFIqQMy5ntJvicC1o2D4+gz/1\nOt3n+SaTiezEDkGTz5OoSN9VqBOi4rl+4JVkxGumusfGzHALmdUjv7LQUGk4rhsTT0J0PSZMdE7u\ndMyYpjzx5TXT+0YGAncKIa6WUvrRJNiL3sAqACnlDiFELlCkM28UsFpKWQIghFgOjAWmAvYyKD8B\ncxohQ7Ngsi0tIpKPehyxui2jFYrWgMWjgGFuSmCtUoNNRJzdQW3Fvqx/7LqR1NR5t8MFeGb83zz6\njDdvD4yXJv39mG6h4MtU9ZDeuO1hPwftIR4ofwDThRD/AHoBPYA84DYhxF1APnAbkA0UuJyXD3R0\nHZdSWoQQViFEjJTS0Mibnp5AVCNKSLuSmeld4ye1Unsji4j3cISbrKzZkq97Tihoqfs2ltYkb2uQ\n9bJT+nLG2O6kJBpHPtWb67nsk9sd+2/96Vl+P7jRbc6Qbn1JiAldcT6/v9voGh6+aiKZmck+z8nK\nSvEau3TQOQAMzzmOGT/OdHQnnHXmE9z2zV/9lrE1/A5cCYa8AcfpSSn3COF/hy6Pc78TQowFlgDr\ngc3Av4GNUsrfhRAzgL8BP3ucamQYatBgVFRU2ShZ7WRmJlNQUOY1XlbiO0RP75xgYyRruNKa5G0N\nsnbJSuLEIZ1ISYzxKetr695x268ptVJc6v7v5MiRCiqiGnYMNweBfLeXn9aVmPgydu337YTXu964\nzLHaRi1cJs7nvU0f0SU5h6NHfPuIrup3MT3TulFQUNYqfgeuNEVeXwonYMVhc1A3+lVESulQ7UKI\nHcCHLs72r4DXgE/QVhd2coAVwAHb+DqbHCZfq42gYuDkiEg5grk2LsTCKBQwwEfoLWiVXvPKD7Dh\niHf47qD2/UiMTqCirpIIU0TY2u4/O/Q+HNK2m1LaY2T2ULqldKF9fAYlNe7RVKOzh3Nl/4scmeJ9\n0nuSHpfW6Hu1RXw5x6foDLcDrkZ7sAeMEGIwcKeU8lohxKnAr8B/hRD32qKjJgEbgJXAW0KINKAe\nzb8xDUgBLgS+R3OUL/S+S2gwGSx2YrptxpxWCJwcWoEUxzxJCb4f9vZKr65cY2vjmhSd6OheabFa\nWoX9/q0N/+b6gVdQ5VGt997ht/l1flZCJgARJqcp+4zuJ3F695Pc5qlq1974WnHo+TjK0EqP6PXp\n8Ic/gAghxCq0ZlCXo/k65gohKoFytBDbKpvZ6ns0b9ijUsoSIcRc4CQhxDKgBk2JtQi+bGSRaQU+\njipCSb3ZQoTJZNgetC3hmhTnyZaj23THh2cP8RprDUoD4Lf89VisFl769XXHWGNWIZEun9dVadw7\n/Dbyyg6QFB38vJTWhi/n+OTmvpnNJHW1x/A+YITO3E/wWNlIKc1AeGTaNPAcOlpaTbsUZbJqSVZt\nPszrX26kc2Yij7XREjB19c6oIl+K45Xf/xkKcUJOvaWefeUHmnQNo3Lz3VK60i2lac2l2iqt49Ui\nDDEyVdn5fpXqQd6SrN6Sz+tfapFCeQUV/L69bbaQuem5xY5tX4pDj6fHB6E0SIjxJ7O7IVrLCiuc\nUN9YI2mowb2vEteK4PP9Kvcc1Zc/Wd9CkoSObtn+h13ePezPbcIEs7Nkd5Ov4erjUPiHoeIQQpwh\nhPDupajwi6IQl1avrK7nqfdWkZff9PITbYEjJfrtTdsyMdHuD8AtR7dRVluu+xLTVkwwr69/t8nX\n8NVzXKGPL+f4VOAJIUQR8CPwg5RybWjEagU08Fs7UBjaCrmvffEHG3cX8cv6g7w9Qy8g7tiipML/\nKG2r1dpqHx59u6axZW8xb93vdEleNPcWshOyOFSZD8DJud7uyrZonslJ6tio86JMkcRERDOove9i\niQonvpzjdwEIIXKAU4B7hRDHA7+hKZF3jM5VwMEjTUs8DJSNu7XKLceqgcxitXL90wvpmJHAkzeM\n9vu8h99eSZ3ZylM3+n9OOGG2WDHhNJ0WVRcDOJQGwA97nFHrl4jzGJk9NKQyhoo/D762UeeZTCZe\nmPhEq315aAkafO2QUu6XUs6RUl4C9ANeQEvIO6bx5Ry3VAa3z/Kug6Xc++pywzo9xxIWi5Wt+4pZ\nsVHLCjt4pJIbnjFO7ykqq+H37YUUlWmmxLyCCg4frcQSxJa/a7bkc99rPwflHtvyStxeFjxzGjwZ\nnzM67BoxNReJTfDZKKURGAFljksprcBq2x+FAZaq4NSykXuLiImO5PH3tC5md89azqzpE7xs2MXl\nNaT5KDXdlvjwp23M/9W9IZFr3/cZlw9l5n+0DshHS6u551XPajYa19uUzbWn9+OEQdkNBj8Ewqtf\nbADg+bm/c++l3nkTgVBZXUdxeS2zP/+Dc8Z19zo+b/d8w3NnjLizSfcOd6KUkztkNF9PSYUTi7aQ\nu3bmAmZNG09CXPNknj79wW9u+5U19WzcdZTn5/7uNl5eVXfMKA5PpeFJny5pJMVHk5IYw4P/XNng\n9eZ8u5mdB0u56pTG1WPzxGxxVp3dvKeIa2cuAOD28wfRu3OaVwjt7kOl5LRPJNqgMOdt/3AWpbaH\nG7uyNn+doSxGjZjaCmrVEDoaVBxCiL5Syi2hEKbNEOE0IX2xdBeXndQnaLfyVBpwbPWSSoyLoqJa\nP5b/vAk9AK21aGlFrd+mvUW/7SctKYazx3q/0fvi1c//4ODRSi47sQ/Pfvibz7mePcI9yclM9Opb\nX2nwORWKUONPaMWnQohlQohrVHiuE18+jqiMQ47tn9bmUW9uVMNEAPYeLgv4fHMQ7fXhxugB2brj\n447ryJkndAMgIsJEeZV/vaPtfLF0V8CyrJEF7C+oaFBp+MP+ggpH7sm1Mxdw7cwF3PaPJYbzzRYz\naw97v0TYOa3biU2WKZwZ16ltVgYIVxpccUgpBwghBgIXAYuEEL8D/5RSKj+Hn/y+rbBRzZ3mr83j\nPz9uBWCOHyG2Z4/vwVdLd3Is5R5mpukXar7mtL6ObbsjPJgUByFv5/fthQ7Tlic3nNWfrllJ/LQ2\njwsn9eL+ZY9RVa9f6r9rcmfO7NF2i26mx6Zxad/zW1qMYwq/fBxSyg3ABiHED2jtWr8SQmwDrpNS\n6ldPUzh49YsNfj34PbErDXCvSaTH6aNzj0kbr2ftwlNGdmHXwTK/vou37p/MgYIKVm4+TG2dhR/X\nNL5MzN7DvnsevHX/ZCJMJqxWKyUVtdw1a7nb8Vv+NJAB3dKJjorkmQ9+ZceBUoMrwWt3TyTWluz3\nf6f2ZdMR6aU0Zk1+mp8PrqK4ppQzPKq9tjXSYr2bNimCiz8+jly0woSXApuAJ9Gq1o5Aa8Kk1oh+\nsOtgKd07+v6BWyxWR3TPPZcc73bMtSaRHhdM6slXv+zRrnMMLTlcP2l8bBQXT+nt13kPXDGUCJOJ\nzllJdM5K4uMF273mHC6qpEO6f9bZf/zXuKSJ60uDyWQiLSmWOTOmYLFa+WXDIUSXNNq7rJwevGq4\n4Uojp32iQ2nY+WLHt17zTCYTY9uw+aZnand2lGjmxF5pPVpYmmMPf1Yci4C3gSlSStcylKts5dGP\nSTz/8QLcM+xWnls7W3d+rY5jdlteMU/9+1dG9stiQLd2vPOdMwbhuY+M7dWuPH7dSDq21+LX2+KK\nw2K18s3Pu5kytLN+ET+b5rhkam/GDWo4c/iMMbmcP7Gn9wGdr+6BN1YA8NZ9zV4oGtCS9sYayPzm\nvZO48dlFjv1Xpo0nKjJC93dXUx/a8jbhwPWDruCBZY8DcHbPU1tYmmMPf5zjg4GtdqUhhLhZCJEE\nIKW83eeZbZi4WG+d6+tNPyrK+6t+6t9afsGqzfluSsNf5syYQk5mkiPnwP7sC/cVx1/eXGH4Ru3J\nK5+s54ulu7jjpaW6xz+cr1lKY6MjSIhr+D1IV2ngu7bVv11Mhg1x8oguvHrXBMd+enLjwqKjIiOY\nM2MKN58zgKtP60tiXLSu0gAorD7aqHu0ZlJinLlSbbF8Srjjz4rjHcDVTpIA/As4NygStVJMmHy2\n27T6CIw6vlf7Zin77VhwhLfe4NBRrRxLVY3v8NLyqjrW7Tji1zU/WrCdicc3Pk9h9ZZ8w2MpCdFU\nVvsXlTXuuI7ExUTx8p3j2bDzCCP7d2i0TAAj+zXt/LZMTlJHR4kVRWjxR3G0k1K+bN+RUr4ghDir\nMTcTQkQArwMDgVrgZqACTRFFAgeBK6WUNUKIy9HaxVqAN6WUb9v6jL8L5AJmtG6BOxsjS3NzsTjX\nq8jaa3dP5H+/7OGbn3d7hdS6xuTffv4gaurMzPrsDw4eqWx0FJDdVBXmCw4HZZW1PnNOAikUObhn\nRtMFMuCr5bv5avlupg7tzOUne+fkuP7d2n0iSfHRhqHCiqZxed8LAXhgxDSs4f6W1EbxZ40XK4To\nZ98RQgwDGlvs5hwgVUp5AnAd8BzwGDBbSjke2A5cK4RIBB4GTkTrQz5dCNEOuAwollKOQ3PSP9VI\nOZqdsZ1GEmGKoH1cO7CauOHM/sRGRxJjM1HVWyx8t3IPr3+5gZKKWkdMvgntgR8XE8U9lwyhd+dU\nv+53xwXHeY3ZVxzh+o+puraej+Y7g/DKAqhgCzB91jK3/T2HyuiQrjmVbzxrQIPnd8xoWhqSZ5a6\n3Ktlgrv6IqJ1TJKh5OI+5/LOuc+3qAzBoG+6FvQwbchNnNBJaxhqMpmUmaqF8GfFMR34UgiRirYq\nKACuauT9egOrAKSUO2wRWwPQVh4AXwP3ABJYLaUsARBCLAfGopV6t/c7/wmY00g5moznw9n+A663\nmsFkZXg/7Q04KlIbX7ftiOPBs2pzvst13OmU4btQ2/Vn9mP9jiMc36u917FwX3E88f5at1VEaUUt\nlroIkuKjHd8TaGXOa+rMXjW4SsprOXikgoyUOG5+3mk9jYzwr6d4jEEZj0C4e/ZyZt40muioSK8S\nMC1Nz9TuTOg8hsSYBCrxHR7c2rjxuP9jf/lBeqTmtrQoCvyrjrtSStkH6A/0kVL2a0Ly3x/AKUKI\nSCGEAHoA3aSUdttMPtARyEZTUBiN2/qXW4UQYVXqs7imBIBFeVqc/t587R+wXk2l3p1TeOiWnm7t\nL08dZdxg55SRXThhYEduPmeg7nHHiiNMNYen6em9bzdx16zlbm/soDm8//zCEub/ut/rGn//11o3\npQENR5MN6N4OgMhI/6LOzrWVKpk1bbzXsaKyGsPQ6NnTJ+iOh4q2/FCNjYxp05+vteFPHscA4Hqg\nHWDSnvcgpQx41SGl/E4IMRZYAqwHNgOuNhejf9mBjjtIT08gqolvmpmZ3tVurS6Zwg9NutNrTm1k\nNZmZyWzPK/E698Y/DeKs8T1YunsVz63Uwnc/vvg1x/G7LhtKx4xE3vpyA/17ZHBcr/bM+u/vXHCi\nINPHisReBiU1NUFX5pairLJWN5R2h8t3k5mZzE+r9rIjr5if1mhKdo2Ow1qvLlW92eLz89oj2mJj\nogznxcZEUlNr5pTRuVx7ziCuPWeQz8+kFxXWtXO6z3OCTYf0do7PF05///7QmuRtTbJCcOT1x1T1\nMTAX8C+xoAGklH+1bwshdgB5Qoh4KWUVWp+PA7Y/rp7FHGCFy/g6m6PcJKX0aSgvKmpaQ6XMzGQK\nCryX/UeqnC1asyNyvOZUVtZQUFBGoUeY5xljchndN5OCgjJeWensheV6/sCuaQDcf5mzBPezt5wA\nFouuLHbs1pqi4kqf80JJXn45D89ZxeShviOeDueX8tJcY9NP1w5J7D1s3BbX6PPuKztAea12nsVs\n/P05AtJ8zGmIFv/Oa6MoKCgz/M2GK61J3tYkKzRNXp8vY36cf0hK+Vij7uyBEGIwcKeU8lohxKnA\nr0ARcD5aFvr5wDxgJfCWECINqEfzb0wDUoAL0TLXzwKMO/YEmYasQUYO6rp6/bhcs8VMZEQTbfAO\nH0f4mKo279U6Ey7UMTu5UlNrXFLl9vMHsX1/ia7iiIww6fa4MFvM3LHoAW2nA7DnVHr5CDy49bxB\n/Ot7yYnDO/uU04gO7Vqm/ue+Muf3mtyERkYKRSD4ozi+E0KcjJZB7rAT2HwMgfIHEGHLOK8GLrdd\n830hxE3AHuA9KWWdEGIGmoKwAo9KKUuEEHOBk4QQy4AatFIoYUlxjVZraETfLLccgUE99MNGf9q7\nmFO6Na1XeIQjqip8yD/qrKHUoV0Ch4/qrwB96bohvTMxm70nvH3/ZEP/xufb/+e232PsZs4eM8nw\nHgO6tWPmTWOMhQAmDO7EknXO4glXniIYNygbk8nk5twPJTNXv+TYTo31LyJPoWgq/iiOv6K96YP2\nTDLZ/h/w67FN2Vytc8irCpuU8hPgE48xM3BNoPcNBg2FvFbbWnhed0Y/N8VhFBL61c55TVYc+UXa\nQ3rDziMM6NauSddqLqrrnD4JI6UBxt9nny6a2W6YyKR/t3Q22Xqrg2+n+O7SvW77B+v2NDlU9urT\n+ropjslDwqsxUpfkTi0tguIYwZ+y6mmhEKT14Vtx1Fs000tMdCSzpk2goroOi9VKu5S4oEn0w0qt\nyOH3q/b5XeyvJZh502hWb8nn08XO3E2jFYfdz2MymbjnkiEOp/TYQb6T63Z5KI7m5qH/Gx7U6wfK\nqOxhLS2C4hiiwVcwIUS6EOJZIcS/bPtnCSEygy9aeNOQOWhnyW7HdkJcFJlp8X5XWm1LWHSaSmWl\nJ3DGmG7u8ww0h9GqIjnBOwr7weVP8tm2bwKSb3vxLnaV7DE87pkvM+PyoZw7oQfdssMjsqZXmtal\n8Mp+F7WwJIpjCX/W7m8B+9ByLgBigfeCJlErweqr+BSNy94OJ6d2c+FZmO+EgforBb2P7quHyYWT\netrOs7K3LI+dJbsprilh/r4lXmYqX7z462uGFY0BpgzTzFG3XTgY0ExnZ53QLaBKxHXmOjcndnNS\nYvOltcXKyIrwxR8fR6aU8mUhxLmg+R6EELcFWa6wJxiP+I+3fsnF4k9BuHLL0aNTKot+d/oFrnbp\nzHfDOQP555cbAPhhlX8P+0euHkFEhMnxoPxxzyK+3Pmd25xn18xybPdM7cYOl9Xfon3L+e+2Lxmd\nPZwaizOS+9f89cRGxhIbGUPPVKdiGNg9g9funkjnTmmNDmuctvhBAG4a9H8cl9lwaRR/2FuWR8eE\nDhRU+VcEUqFoTvzqAGjLmbDatjsAx3zcXzBWB0v2/9zmFMchF4f46AEd3KKPzp7Qk4Vr9rF9fwnf\nrXQqjrGDsrnsRO9iggC5HiYiT6XhyR1DbuTORX+hQ0IW3+36iW92/QDAikNr3Oa9veHfju1R2cO4\nqv/Fjn2jcuaB8sYf7zG20yj2le3n/hF3NOoa9y99lPI6/4s/KhTBwB/FMQtYDXQUQnwFjATuDKpU\nrQB/TFH/2fwJl/e7IATS2DCZwdo8D7nm4tetWuWYMQM6cN2Z/b2OR+mUAbnuDO95RrSPa+ezH0VU\nRBTJ0UnUmmsdSqMhVh5ay/ic0XQPsMTF2xv+TWHVUW4//gZ+2LOQvPIDbD7q3stj+YGVANy64D4A\nBrcfQMekbObtnu8277ExM8iId4+Mq7fUK6WhCAv8qVX1MXAmcBuav2OIlHJusAULd2IjG27Q8/PB\nVRyqOGx4PDG6+ZzlhyryiR/xI1HZu5rtms2BfcWREBvtaDjlSlPzH4Zneyf/2Xl5klY8OTIikqKa\nwPo2+PJ7GPFr/nr2luVx79JH+HHvIi+loce6wo1eSgPg4V9msuawVqzhqx3zeGHtq9y56C8By6RQ\nBAN/alXNlVJeDPw3BPK0Gvx1RW4p2k52on4znoo677yGqvoqYiNjAy4X/fjK5wCI7iqpP9Q9oHOD\nyckjuvDD6n2McmloZH/bnnvRq17zMwIMV86I068P9crkmY7v0F54MpiU1RqXQ2ks72z8gHc2fqB7\nLNIUycXiT3yw5VMeHHlXs99bofCFP6aqXUKIa4Gf0ZovARAuDZTCnW1FO5jUeazf8+9Z8gjREdE8\nP+ExwxIk9ZZ6DpQfoktyTthH0+w+qEX9REV5y1lTX8PuQ+4O5yduGBXgHdyv2yEhi8OV+X4p3hkj\n7mTlwbUszFvW4NyGOFhxyOfxh0fdQ3RkNBV1lRysOMx7mz7ymnNq7hTG5ozioZ99t5l5ZPS9ZCVo\nEfFjOwX6fSkUTccfxXGxzpgVZ3juMYp/D+yEqPiAr1xnqePz7f/j/N5nsb5wI73TepIQHY/ZYsZk\nMjlMFmf1OJVT9bLNTY2pBhMcttoq4EZFeD/IK+urqfBoyRqjk91dXV9NXJT+SsRidda4yohL5+HR\n9/gl12ndptIlOYcuyTmc0+t0vt4xj/n7lrjNKaw6Svt4/zLwX/rtTcNjs6c849huF5dOl+QchmQd\nR2lNKfP3LWVU9lByU7o45sya/DS3Lbzf8Hp2paFQtBT+KI6xUsoDDU9T6NHV5YHgSYQpgtzkLuwq\n9U5AW5i3jKyE9szd+gWgPXwcRftsfL1zHifnTmL+XvcHnimu+c0mjcE1qa+6zkx1fQ3binc4xirr\nqrzyNzxXUEv3/8JH8nPA/QFsx+4svrjPuYyxdYbzRfv4DB4edY/bai46Ikp35fbILzMBzezV3ERH\nRJER346L+pzjdcxkMvHixCeYvthRSJonTvgLR6qL6JnardllUSgCxR/F8W+gaUWU2iBGFqKk6ES3\nyJcOCe6Zx1arlZLaUnaW7MFitRDloyKuXWn44vaFM7wHreHRTnOxS/5GhMnE+5s+Yl3hRsdYVZ17\nyXnPWlJWq9WhNIz4euf3ABRWHyE6ouGf86Nj9N/kLT4SOufKz7kj6+oGrw1aF75rBlzKX3/+u1/z\njYiJjGH2lGdYnPczlXWVpMelkR6nqv8owgN/FMdWIcT7ePs4WqxtazgT5fHweum3N3luwmPE20wt\nz6x5mb0uWcRGtviEqHgq66t0jzWIKTwy0H/b5mzimJoYw7otG92OV9a5f7437pnkth9Ivan5e5dw\nXq8zAxfSxoYjmw2PJUUnsrVwJ+k0bCK6qM85pMel8dS4h1hxcA1TuzStK+DEzic06XyFIhj482oa\nC5iBUcB4lz/HNCYDH0eUyXsFUVBZ6Nje61F6oryugnuGeSfin9XjVLf9ht68AQal2grvhYni2LDT\nmV+h1wHQU3F44plkWWs27tl12/HXByidO3oRbnbm7VnAX+c/y9MuJcyN5OqQmAVASkwyJ+dObnqP\nFYUiDPGnOm5YlDEPN+osdbrjeqGfeeUH6Zqi3yBof/lBuqd69xn3vP7S/b/4lCc6IpouHVL4owRy\nO4RfYn9sjPcD9ItN3xPdsw5zYScsJVlex81W9+ZO0xf/lVmTn8ZkMrHxyBZeXedc9PZrp59p7kqH\nBO972PGlOOzsLdtPjbmW2EitwOKaQ7/xzqYP3eb4Yy5TKFo7/uRx7EOnNJOU0vtpdwxRZ/HufQ1Q\nb/XuZPefLf/lhE4jAor1/2x7YFVe/zHpSb7L0+z94bHeaJhdxfuIyoCojENUrXKusDYf2coPexcx\nWSeMedPRrXwsP3fLFvf3YR0b6b3qCZS7Fv+Vv4ycTk5SRy+loVAcK/jzL26cy3YMMBVoVMqzECIJ\neB9IRzOBPQo8gFb7yu5RvltKuVYIcS9am1h7B8BvhRCpwAdAKlAOXCalNK43EUTSG9FtbcYy7w68\nTc0ev+W4axyltU1h2DoWrERm7aWouuHM7fzKQkpry5i17i0AthZt95rz6rq3vcaMlLidfu36sPno\nViJ0zIh63Db4en4rWM9lfS9wJCu68vdVL+pGeL00qWkOcYWiteCPqcozVnSbEOJ74IVG3O9q7ZLy\nASFEJ2ABcAi4Rkq5wT5JCNEduAQYg6YkltruOQ1YJKV8VghxI3C/7U/ISYhO4J5ht9HOIHPZk/3l\nB3XHx3ca3WgZPB9edsWxryA8wnEBItIPE9NtMy/+alx6BeDiqT14dIX3w7g5sEdM+UoKjI6Ips5S\nxwkdR9Ivow/9MnybvvQUimdghELRVvHHVOUZitsF6NnI+xUCx9m20237ekwGvpNS1gIFQog9QH+0\n1c61tjlfA4HZc5oZPd+EEaW1+iW5B7Tv11ziGDrsWxJTjBZye6T6KOmxaYY1oyYMyearJbqHABiW\nNZi1+esaJYPdX+TrwR4TqSmO+OjgdWhUKNoK/rwiPeSybQVKgZsbczMp5UdCiKuFENvRFMcZwEzg\nMSFEe2Az2qoiGyhwOTUf6Ogxbh9rFUQavO32sFVgndh5LIvzljfpHvYVhylMoqoAImKdTueYyGiS\nY5J0fT2+zGuvTJ7JF9u/9Rq3+xoaYnT2cHaW7GFCzhjDObcOvo6vdszjpK6TGryeK33SerK1eAf/\n1/+SgM5TKFoz/piqJgshUqWUJaD145BS+rY7GCCEuALYK6U8VQgxGHgbeBJYL6XcIYR4DbhV51S9\nV2m/Xq/T0xOIimpaSGRmZtPbhLZLT/J57cGVIiDF8dLpj5KZ7C6X6aDzK2kOmZuFSGewwOHKAsNp\nGRnGkWAdslK5PO1sr5Igx3dvOJIK4Jz2U5nSdxQpccbfSWZmf4b39F3O/dEpd/HIAqeF9t3zXiAh\nOvCSMqEgbP7+/aQ1yYy+k/kAAB81SURBVNuaZIXgyOuPqerPwMmAvcPQh0KIz6SUs3ycZsRY4HsA\nKeU6m5/jKyml/enyNVptrIWAcDkvBzhg+5MNlLiM+aSoqOEwS19kZiYH1PnNyBzzo/xZd7792mVl\n1brHPXlk9L0criwgqjqegmp3uZxlM6w+ZbZYrZhouN3owl/zKKuq4+yxjau2O/H4Tvxc8ofX+PSh\nt/DjnkVuSXcFhfryvjjxCcdneXb8o9y79BEARnccHnBHvoKyxnXws9MeZ9vbsZ1GUVFcTwVNu2Yw\nCPQ329K0Jnlbk6zQNHl9KRx/EgCvBFy7EZ0MXNYoSWA7WiIhQohctEiq74UQ9loKk4ANaE7zM4QQ\nMTblkgNsAn5Ai7QCOB+Y10g5gkbHJP0S6sv2r/AaE+m9HNv+LJ+mdp1AVkImg9rrvxk7fBwNXOwv\nb67gobdX6R6zWq3UmzVn8r9+2MoXSxvu77Fx91EKS6oc55stFqpq6tl1sFQ3GbFXWnduGeyeHmTU\nGCvGljMBuL3dHzAINmhuuiTnuO3bgyHO6XlaSO6vUIQj/vg4IqWUrvGOVvxvR+HJG8AcIcRi271v\nAtoD84UQFcB+4G9SykohxD+BJbb73SKltAghXgb+LYRYChQDVzRSjqDRIyWXTUekX3OHZQ12bKf6\nCO+9RJzHR/Izt/l6uK44istrSEvSbzaVX2ScsX3d0wsBeP5WZw5FSXkNqQbXKq+q4/mPtIZDc2ZM\n4ZPFO/huxV6S4qMpr6oj2s8ayntK93mNPT/hccP504fe4t+Fm8jAjL7sK9vPwCxtAfzw6HupMdc0\naxMuhaK14Y/i+EoI8TOwFG2FMhX4tDE3k1KWAxfpHPpYZ+4rwCs654d1U+6pXSf61aJ0XKdRbtVc\ne6Z24+r+l5IYncBsj1yF8TmjOaHjiAbLV7h22Ht/nqRrhyT+NN79yV1cXmN4vquD+u7ZTn/L9FnL\nGTMgmxvO8l7pVNY43ynWbS/kuxVafanyKlvmu48S78+e8iD3fv8kAK+tf8freFyUt7K6rO/5RJgi\n3VYiweTk3MkkRMVz+sCJVJdaiY6IUtnhimMef5zjTwghFqGZmKzAn6WU3nYXBaBFDl0qziM7sQM9\nUnOZsfQxKuq9/SyX9j3fbd9kMjEiewi1ZvdSI+NsjXr8q3lkN1VZ+X17Ib9vL/RSHPX1+g/ytbKA\nf32/xfDKv2w8xFWnCN3SIXZe+mS915i1IgUynE2OLnQpI56b1pmeqd3ZUeJuDhuVPYxze52he49Q\nNy6KiYxhStcJJMcmUR2G/gyFoiXw69VJSrkMaHqbtGOEcTnOpL6xOaP4Yc9Cv891XTXoZSf7os6m\ndEyxxqaojxd6Z2MfLa1m9ufeTmxPflq7jzPGdHMbM5t9N42ymt3LfHh2Q9R7e7+qv17vMIVCES6E\nR+OGNkygSXlREVHcdvz1PDL63oDv9flmLVYgpvtGwzlrpHdI7KGj/kWebdpd5DVmNhvnX+S0T2TC\naN++gHBvfatQKLxRxtog05gHoz+VXpuTH1d7O6b1SE2M4YOftvLTmjwA3rhnIs98+BsAyQnRlFVq\nK54LJvXk9NFaYuN9S75znD8go6/XNWvM7j6XGwf9X+AfQKFQhBSlOIJMOJYBsXO0tJp2KXFs2OVf\nncgVm9zzPm96brFj2640AMwW5yrE7t/p305ww6CrvK65s8S9FNpAHeWiUCjCC2WqCjJ6K44RHYa0\ngCTe2MNyXR/0nrx0xzjDY0b0znGGFp/YdSIAp3abquvP8IyOUo2PFIrwRymOIBNhW3EMzHAWM8z0\n6EMeSo7rmeHYfubD37xqRE06vpPbfnKCf2GvL94+jvsuHcJpo7oiujp7Y9ubMRn1VvfV1U+hUIQn\nylQVZJyFB51jZot3s6dQsGVPEet3HHEbczUxAVx1al+mDO1MZKSJzDQtU7tPlzS27vPdTyM1MYbU\nxBj65rqXmV+4TwvG86cXxrQhNzU4R6FQtDxqxRFk7D4O1zf7UGYdW1zua3dku1JVU8/447QKs3dc\noFW875yVRMeMRKIitZ9HerJ+1nggRPgRJNA7vbHV+hUKRShRiiPIHKzQHMoFVZoDuktyjs/y3k2h\nY5J3T22LD/8FaBmddbZcjIwU/V4UvTv77nY47UL9UihV9c58Er1e7AqFonWiTFVBZvVh7S3/cGU+\nAKfmTiG6GXpf6xEV6f3XabZY8VVVvrSilhUbD9vO118VjD+uI/sLK2iXHMuni3cCEB8bSVWNZnLr\n0SlF97xvdjpLr7SPz9Cdo1AoWh9KcYSaICa8ReiE/lZW1xMbbaw5Zv7nV8d2dJT+AjQ6KpIrTxZY\nrVZ65aTStUMyFdV13PfaL4zom0VSvL4i3Fq0w7Ed5We/b4VCEf4oxdGG0Av9Xb+jkInHa6XB+3ZN\nY8teYye3kanK9fqiq+b8jo+NYs4Mz67C7hyocNaoSonVX5UoFIrWh/JxhJhgpgPqKY735jlLvNuV\nxuUn6WemB7P8h1FF2XuG3QZo5coVCkXrQCmONkRmgn9+hJKKWrp3DI/2l91TuzJ7yjN0SMhsaVEU\nCoWfKMURcoL3Vn/D8EsBsFTq9ze3E2GCUf30OxUqFApFQyjF0YZIjdP8CNZ631Fb8bFRRES4K7BX\npo0PmlwKhaJtEVLnuBAiCXgfSAdigUeBQ8BraCkF66WUt9jm3ovWX9wKPCql/FYIkQp8AKQC5cBl\nUkr/KvSFCSEpeWhwk5SEaEor6xgzMJuFv+53O5YYF5wQYYVC0fYI9YrjakBKKScDFwAvAf8A7pRS\njgVShRCnCSG6A5cA44AzgReEEJHANGCRlHIc8Blwf4jlbzKh6D8RmezdNwMgN1tbkcRGR/Llsl26\nc4KByuFQKNoWoVYchYD9KZIOHAW6SylX28a+Bk4EJgPfSSlrpZQFwB6gP1q/88895ir8xGLRMsQj\nTMbF3neV7GVRntZv/EjVUQoqjxjMbBh75dvxLh0RFQpF6yekpiop5UdCiKuFENvRFMdZwGyXKflA\nR+AIUKAznu0ybh/zSXp6AlG+Uqf9IDOz8RFI0ZHRjpauAKmpCU26XmPIyEjCbLGQX1INQIesZPrk\npiP3OFcmdpluXTALgGG5/Xn4l5kAfHzxaz6vX1BxhOTYJOKi3GtaTeo2mh92LGFcr6Fkpup/5lB/\nF01ByRo8WpO8rUlWCI68ofZxXAHslVKeKoQYjLZ6cC1iZPQirDful82nqMi/tqhGZGYmU1BQ1ujz\nE6MSKDY7P+KqXevpGt2tSTIZYfQD+eX3PF7+ZD2VNfUAbN+fR3qaRVvH2SgoKMNidfYP319Q6Nje\ndeAQSdGJuteurq/m7iUPkxmfwd/G3M+hisNsOLKFnMSO/LBjCQDFRZXE1Xp/h039bkOJkjV4tCZ5\nW5Os0DR5fSmcUGeOjwW+B5BSrhNCxAOuXtkc4IDtjzAYz0ZTNvaxsMbTKLS9JHS+BTvVtWaH0gB4\n6JentNAETnWMrTy4lnUFGxz7r/z+T8f2/UsfZUqX8Zzf+yyva5fXVQBQUKWZtJ5e/TK1FvdS7eHc\nBVGhUAROqH0c24FRAEKIXKAM2CyEsLeZOw+YBywAzhBCxAghOqEpiU3AD2iRVgDn2+aGNZ7O8L7p\nvUMuwz/+u85lz7tarimmivc3z2Vd4UbDayzYt1S36ZJrH6hbF9znpTTAu8ufQqFo3YRacbwBdBNC\nLEYLq70ZLVLqKSHEcmCHlPInKeVe4J/AEuBT4BYppQV4GRguhFiK5kB/NsTyB8wFHm/px2cNDM2N\nTfrNovr08O6tYYqp/v/27jw+qups4PhvsgGBAGkIAgkiiDyERaTsAkIAqRa3oqUgIqCWlipF8RXb\n6otSl1awigJWirG+lpYWP7iUvlAQkE1KRRBZhKcCIptAQCOENSHpH/cmTpKZJGOSWZLn+/n48c65\nZ+597jjOyT3nnueU65Drv9hYoiwvv+xFqerFlT4h0RgTWYI9OJ4NDPOxq8TsM1WdCcz08f5bqia6\nqtG6Yasir6OC1FbX7rSGvDMJXPhP1yLlSQ1jOeBu3/uDjsx+axv9etRnQzm6Qbcc20b/1N5Fyi56\njYv4kt68j988VcaYyGT/R1ex4qv9eTzBaTg8ceeJjjtfonzL+ZWF/9W7SDIZD6fz+L+eKdcx68bG\n88r2eWSdc5IlTuryM7af2FmiXqfkDvy4wygnjiDMWzHGBJc1HEGWnZMd2gDqFp0c6PF4+PJ86euJ\nF9jiNXgO8JsPZhRJnV6gZf1LrcEwphqzXFVB8Ltrfl24HRcVfgPFeaV0N81K93834qvRACzTrTHV\nnN1xBEHtmG8WSAqnP8TP5p6lTkwdv/sHt0gv953DL7pN5MtzWXx0bBsdGqVVVojGmDBkDUeQ5Zd8\nGjZkDmUfoXXDlkXKJnedQFLt7xAfW4codzzm6qbdfD5R5a15QgrNE1LolNy+yuI1xoQH66qqYVLr\npRRu787aC0C0ux74pQmptKjfnHpxdQsbDYDkOo2CG6QxJqxZwxEkw2UoKfWacmlCStmVq4inzkkO\nZn+TTn3R3qWcupDNNSm9ALjtipt8vq9pvdIXfZr03Z9VXpDGmLBnXVVB0jelZ8izxNbuuL5E2ecn\nD5Dnziav5WeGd4ekNO7rdA+x0bE8v9lJeCiJrdGvdgPQrIyGxRhTvVjDUe3lU1o+yAt5Oax206jH\nRPnOIuzxeEhLagPAjP5PExsVw5mcs7y89TW6XnJVqQPsxpjqx7qqqrmbercodf+O47sKt8szObFg\nFnh8bB0mdRnPNam9KhagMSbiWMNRzV1/9aX07tjE7/4NRz4s3I63OwdjTDlYw1HNnbpwiruHtGPu\n5P7EeEpf0CrBkhEaY8rBGo5q7tMsZ/2P6Kgoct1Mtje1uq60txhjItT776/lqace97s/I2MOCxf+\nrcLnsYajmpu3c0GJMl9rZhhjTHnZU1U1kAe45fLv8/aexaEOxZhKt2DlbjbuOlapx+zWtjHDBrT2\nuz83N5dp057i8OFDXLhwgXvu+Sndu/fktttu5PXX/0Z8fDyzZs2gVavLAdiwYT3Hj2cyderTJCc3\nBmDx4kVs2bKZrKwsPvtsL+PGjWf58qXs2/cZU6Y8Sfv2HViwYD4rViwDoG/fftxxxxj27NnNk09O\noX79BjRrlloY08KFC1i16l0uXsynb9/+jBhxR6V9HtZw1EDRnhiiiz16+3C3n4coGmMi37vv/pO4\nuDhmzfoDx49nct99P+Gvf33Tb/2jR4/w8suvlsgFd+DAfl566RUWLXqbefNe49VX/8ySJYtYvnwp\niYmJLFmyiLlzXwdg3LjRpKcP4rXXXuGuu8bRt29/nn32N+TmwuHDh1i1agXz588nM/MU48ffTXr6\noEq73qA2HCJyNzDKq6gr8CFQFzjtlj2oqptE5CGcZWLzgamqulhEGuCsHNgAyAZuV9Uvg3YBEeDG\nVt9j0d6lpdZpUT+Vj45tK1J2aUKqn9rGRJZhA1qXendQFVR30rlzFwAaNUomLi6Wkye/9ls/La2d\nzwSibds65UlJjbj88iuIjo4mMTGJ06c/5tNPlfbtOxIT4/xsd+zYid27/8O+fXvp0KETAJ07d2HD\nhvXs3LmDgwcPcOedd3LhQi5nzpzmyJHDlXa9wV4BMAPIABCRfjirAbYHxqpq4WIPItISGA70wmkk\n1orIUpxlZlep6nQRGQc87P5jXNddNpDcvFyW7FtRYl/BbO9WDS5j9scZIYjOmOrKQ75XBtOcnBw8\nnqgijUNubm7hdkxMrM+jREdH+9x2ju37HPn5EBXlnCcvL6/w+L169Wb69N+SmfnN8p6bNpWerLS8\nQjk4PgV4ws++dGCJql5Q1Uzgc6AdMBB4y62zCKi8e69qJMbPUq0FiQujg7QKoTE1RVpaOzZvduZE\nHT16hKioKBISEoiPr8uJE8e5ePEiO3ZsK+MopWvTRti+fRu5ubnk5ubyySc7aNNGuPTSFuza5azE\nuXnzJgBE0ti8eRNnz54lPz+fGTOe5fz5cxW7SC8hGeMQkW7AAVU9IiIAvxaRRsBOnLuKJkCm11uO\nAU2LlReUlSoxMZ6YmNLnL5QlOTmhQu8PpuTkBC7sP1eiDCAm1vmrpHHjBrRMbM5nXx0oUSfYIu2z\njRSRFCtEVry+Yh0+/FZ27tzKpEk/Iycnh6eeepLk5ATGjLmTX/3qQVq2bElampCQ4KzNEx8fV+I4\nCQm1C8sbNKhD7dqxRbavvFIYOXIEDzwwnvz8fEaM+BEdO7bh/vsn8Mtf/pJ33nmD5s2bc+bMGTp2\nvIK77hrDyJEjiY6OZtCgQaSmJlO3bi3q1atd4c/bkx+CBSJEZA4wX1VXicgPgK2qukdEfg/sAeKA\n06r6glt/HvA6MAvopqpfi0gMsF9Vm5V2rszMUxW6wOTkhCK3euGsINZ7V04uUv5Mn8dYvn817+5f\nBcDM9N/y9p7FrNi/prDO7AHTghkqEJmfbSSIpFghsuKNpFihYvEmJyf4TXIXqj6L/sB6AFV9S1X3\nuOWLgI7AYZy7iwIpbpl3eUGZKcPB7MOFjQY4XVY3tBwcuoCMMREt6A2HiDQDslX1goh4RGS5iDR0\nd/cHtgMrgSEiEufWTwE+AZbhPGkFcCvwz+BGH5ne/XxVibI4PynUjTGmLKG442iKMz6BquYDfwBW\niMgaoDkwW1X3A3OBNcBCYLyq5gEvAl1FZC3OAPr0EMQfcXZ99WmoQzDGVCNBHxxX1U3A9V6vFwAl\n8mKo6kxgZrGybOCWqo6xOhvcIr1w+5k+jzFv1wKGy9AQRmSMiTQ2c7yG+fSrPYXb9eLq8tMrx4Yw\nGmNMJLIH+muYz07uD3UIxpgIZw1HDTO63fBQh2CM8TJkyEAAXnjhdxw+fIjTp7P54IMNIY6qdNZw\n1DDnL54PdQjGGB8mTnyQZs1SUN0V9g2HjXFUQ10ad2LTsY997qsfFzkzdI35Nt7c/Y8SSTwrqnPj\njgxtfUOpdRYvXlSYLr1Hj15s2PA+Hk9UYUrzY8eO8sQTUwAnb9Wjj04lJeWb5KL33TeOSZMm89xz\n0zhz5jSJiYksWvQO8+cvxOPxsGzZElR3MmHCpEq9tm/D7jiqoVrRtfzuu7xByyBGYkzNcvToER59\ndCoffvgBL72UwezZc1m9eiVHjhzhxInjjB37Y2bOnMOQITfx5ptv+DzG7bePYsCAaxk5cjStW7dm\n+/atAKxdu5prrw2P1TvtjqMaatXwMtZ/8YHPffXi6gY5GmOCa2jrG8q8O6gqaWntClOaT5jwE4DC\nlOZNmzZjxoxnyciYw6lTJxFJK/N41103hBUrltG2bTu++OIwbdu2q+pLKBdrOKqhHk2+S1LtRF74\naE6oQzGmRomJiS1MaT558iNF9j399FR69OjJLbfcxnvvLWf9+nVlHq9nz97MnfsymzZt5Oqr+1RV\n2AGzrqpqKMoTRZvEy+l6yVWhDsWYGqcgpfm5c+eKpDTPysoiJSWV/Px81q1bTU5Ojs/3ezweLl68\nCEBMTAxXXdWZjIyXGTz4ep/1Q8EajmpsdLvhjOs4uvD15K4TQhiNMTVDkyZNGDZsBPfe+2PGjRtD\nUlIStWrV5uabh/L889N58MGfM3Dg99iyZbPPp6dE2rJy5TL+8pc/ATBgwGDAQ2pq8yBfiX8hSase\nTDUxrXpxWzK3szVzB6PShvlcrjJUqsNnG44iKVaIrHhDEWtGxhyaNGnKkCE3BfzeqkqrbmMcNcBV\nyR24KrlDqMMwxgTooYcmUqtWLcaMuSfUoRRhDYcxxoSp6dNfCHUIPtkYhzHGmIBYw2GMMSYg1nAY\nY4wJSFDHOETkbmCUV1FXoDfweyAf2Kqq4926D+EsE5sPTFXVxSLSAPgL0ADIBm5X1S+DeAnGGFPj\nBfWOQ1UzVLW/qvYHHgP+D5gBTFTV3kADEbleRFoCw4E+wA3AcyISDdwPrFLVPsCbwMPBjN8YY0xo\nn6qaAowF1qjqRrdsETAIZ13yJap6AcgUkc+BdsBA4C6vuv8IbsjGGGNC0nCISDfgAJALfOW16xhO\no3ECyPRR3sSrvKCsVImJ8cTERFco3uTkyElFHkmxQmTFa7FWnUiKN5JihaqJN1R3HPcAr/ko9zdT\n0Vd5uaZAx8REh89UaWOMqQZC9VRVf2A9zt1Dkld5CnDY/adJGeUFZcYYY4Io6A2HiDQDslX1gqrm\nALtEpCBf8FDgn8BKYIiIxLn1U4BPgGU4T1oB3OrWNcYYE0Sh6KpqijM+UeB+YI6IRAH/VtXlACIy\nF1iD8zjueFXNE5EXgXkishbIAu4IbujGGGOqfXZcY4wxlctmjhtjjAmINRzGGGMCYg2HMcaYgNh6\nHH6IyPNAT5zB+Yles9uDGUMH4B3geVWdJSLNgT8B0cAXwChVPS8iI3EeMsgD/qCqGSISizNXpgVw\nERirqntFpBM+coNVQqzTgL4436nfABvDMVYRiXfPdQlQG3gC+DgcYy0Wdx1guxvvinCMV0T6A28A\nO9yibcC0cIzVK+aRwGScychTgK3hGG9V5fkTkUHA0278i1X1ifLEY3ccPohIP+AKVe0F3A28GIIY\n6gIzcX4kCvwamK2qfYHdwF1uvSk4qVr6Aw+IyHeA24EsN6/XUzg/5uAjN1glxJoOdHA/r+vcc4Rl\nrMCNwIeq2g8YBjwXxrF6exQoSOgZzvGuLshHp6oTwjlWEUnCyZlXkBPv5nCNtwrz/L2IM7WhNzBY\nRNqVJx5rOHwbCLwNoKo7gUQRqR/kGM4D36foJMf+wN/d7YK8Xj2Ajar6taqeBd7H+RIMBN5y6y4H\neotIHNDSR26wilrDN/NrsoC64Rqrqv5NVae5L5sDB8M11gIi0hYnV9v/u0VhHW8x4RzrIGC5qp5S\n1S9UdVyYx1tgCvCMn/Ok4+b5U9VMwDvP31vedUWkFfClqh5Q1TxgsVuvTNZw+OadEwt3u4mfulVC\nVXPdL6m3uqp63t32lb/LZ7n7pch3y3zlBqtorBdV9bT78m6cL2BYxlpARNbj3LrfH+6xAr8DJnm9\nDud424nI30VknYhcG+axXgbEu/GuFZGBYR5vefL8lRlrOeqWyRqO8gnHfFeB5PXyV16p1yUiN+M0\nHPdVICZ/5ZUaq6peDdwEzCt27LCKVUTuBP6lqp8FcP5Ayysr3k+BqThdPqOBDIqOo4ZTrAXHSsLJ\nWDEG+CNh/F1wVWWev3LHag2Hb8VzZTXDGSgLtWx3kBQCyOvlDuJ5cK7BV26wChOR7wGPANer6tfh\nGquIdHEfMkBVt+D8sJ0Kx1hdQ4CbRWQDzo/G/xKmn62qHnK7AvNVdQ9wBKebN+xidR0F1rt393uA\nU4T3dwEqN8+fv7plsobDt2XAbQAi8l3gsKqeCm1IgNOPequ7XZCr699ANxFpKCL1cPpe11I0r9eN\nwHul5AarEPeJjenADV4rMoZlrMA1wINu3JcA9cI4VlT1R6raTVV7Aq/gPFUVlvGKyEgR+R93uwnO\nk2t/DMdYXcuAASIS5Q6Uh/V3obLz/KnqPqC+iFwmIjE4g+nLyhOLpRzxQ0R+i/Mjkwfcq6ofB/n8\nXXD6ti8DcoBDwEic29TaOINeY1U1R0RuAx7C6WOdqap/dp+keAW4AmegfYyqHnCfmpiD80fDv1V1\nEhUkIuOAx4H/eBWPds8fbrHWwelCaQ7Uwela+RB4Pdxi9RH748A+YGk4xisiCTjjRg2BOJzP9qNw\njNUr5p/gdK8CPInzGHlYxuv+Jjypqte7r32eR0Qm4PxW5AOPquoKt8Gbh3OXkgXcoapfi8g1OAPt\nAAtV9dnyxGINhzHGmIBYV5UxxpiAWMNhjDEmINZwGGOMCYg1HMYYYwJiDYcxxpiAWMNhajwRucP9\ndxMReaMKjh8lIrtEJOBZxCKyyn3s89uc15ZWNlXCHsc1NZr7o7xTVdtU4Tm6Aw+o6oiqOoePc1b5\ndZmay9bjMDXdq0ALEVkGjAPWqWqqiLwGHAfSgPbAL3BmB1/p1ilY++BpnJnEdYDVwGRVLf7X2GCK\nzcgVZ+2KR3Cy83YDNuCsBfEDoBFO6paDIpIPxOKkVU8CUnEmnL2nqhNEZAwwSFUL7ppW4UxkG1Vw\nXao6WESGARNw0mJkAveo6omKfXSmprKuKlPTPQZkqupgH/suUdUhOLPiZwP3At2BMW76iR8CKara\nT1W7A61x0jYUV6LhcHXHSX/SFWemb5aqpgObcFPeFNPZLe8GjBWRxPJcl5ub6xGcBqYPsAr4VSnv\nNaZUdsdhjH/vu/8+iNPtkwUgIidwVlJLB3q5f+XjlrX0PoC7jkt9VT3k4/g7C3J7ucdc73W+Bj7q\nr1PVi8BZETkOfKec19ELJ132UhEBqAX4y7ZrTJms4TDGv1w/2+B0+ZzHWUa0tPw+A4D3ynH84q99\nDaT7iqF4t1icj/edBz5QVV93Q8YEzLqqTE2XhzOG8G2sA4a6mUURkSkickWxOv66qSrLSZyEjYhI\nY5zxGCh6XRuB7m7GWkTkh+7aKcZ8K9ZwmJruMHBERDbhLHkbiDdxurPWi8i/cNKI7y1Wpx/OoHlV\nWQbEuOt1PMM33V3e1/U1MBH4h4iswckGu6EKYzLVnD2Oa4wxJiB2x2GMMSYg1nAYY4wJiDUcxhhj\nAmINhzHGmIBYw2GMMSYg1nAYY4wJiDUcxhhjAvJf4+MYGXe/hRIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb7537568d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gA7V9vP0Korn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simulate(period, threshold_buy = 0.33, threshold_sell = 0.38, unit = 0.1):\n",
        "  currency = 10000\n",
        "  share = 0\n",
        "  init_share = currency / price[29]\n",
        "  bitcoin = []\n",
        "  result = []\n",
        "  for i in range(period - 1):\n",
        "    cur_price = price[i+30]\n",
        "    estimate = eval(price[i:i+30])\n",
        "    #if (i % 100 == 0):\n",
        "      #print(estimate)\n",
        "    if (estimate < threshold_buy):\n",
        "      buying = unit * (threshold_buy - estimate)\n",
        "      if (currency > buying * cur_price):\n",
        "        currency = currency - buying * cur_price\n",
        "        share = share + buying\n",
        "      else:\n",
        "        share = share + currency / cur_price\n",
        "        currency = 0\n",
        "    elif (estimate > threshold_sell):\n",
        "      selling = unit * (estimate - threshold_sell)\n",
        "      if (share > selling):\n",
        "        share = share - selling\n",
        "        currency = currency + selling * cur_price\n",
        "      else:\n",
        "        currency = currency + share * cur_price\n",
        "        share = 0\n",
        "    elif (i > 5 and currency + share * cur_price < 0.9 * result[i - 5]):\n",
        "        currency = currency + 0.5 * share * cur_price\n",
        "        share = share / 2\n",
        "    result.append(currency + share * cur_price)\n",
        "    bitcoin.append(init_share * cur_price)\n",
        "    if (i % 10000 == 0):\n",
        "      print(currency)\n",
        "      print(share)\n",
        "  return result, bitcoin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_erNQ9u1p6L5",
        "colab_type": "code",
        "outputId": "798553e2-d32d-4e22-8d52-a65f5a64809a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 719, 7, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 239, 7, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 239, 4, 32)        3104      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 79, 4, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 27, 2, 64)         51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 1, 64)          102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 161,185\n",
            "Trainable params: 161,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6nZf9f_-tAce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EuWelysdRK1O",
        "colab_type": "code",
        "outputId": "c3d1179d-266c-495a-c458-41c2f9fc8781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101440,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "metadata": {
        "id": "yzJMi1vpPUdh",
        "colab_type": "code",
        "outputId": "f3cea163-4a9e-4e3b-f184-90365d64a907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "result, bitcoin = simulate(70000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "0\n",
            "0\n",
            "10.157098549815501\n",
            "2739.9502799999927\n",
            "6.928200313310433\n",
            "212.27409000000006\n",
            "9.781229436564729\n",
            "241.35821666666436\n",
            "9.764368106884756\n",
            "0\n",
            "9.986641076074891\n",
            "348.72521333333333\n",
            "9.598373339169314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7qljINAdivbt",
        "colab_type": "code",
        "outputId": "788ba9e7-5fe7-45ac-a5e6-89fe88b47bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "price = np.array(bitstamp[120000:201440])[:,1]\n",
        "def eval(price):\n",
        "  count = 0;\n",
        "  for i in range(1439):\n",
        "    if (price[i + 1] > price[i]):\n",
        "      count = count + 1;\n",
        "  return (count - 300) / 1440"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0a51e9c28d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbitstamp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m201440\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1439\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bitstamp' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "R6QaQOHtoL4N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = tf.reshape(tf.stack(X[0:0+200]), (200,60*24,7,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UsrRwDTmmJij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(inputs, steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9USfmyJRonGf",
        "colab_type": "code",
        "outputId": "af371fea-0a17-44da-a694-86f95b1ce118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_hat.any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "Ugq1-AHNiJa3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simulate(period, unit = 0.1):\n",
        "  currency = 10000\n",
        "  share = 0\n",
        "  init_share = currency / price[1439]\n",
        "  bitcoin = []\n",
        "  result = []\n",
        "  for i in range(period - 1):\n",
        "    cur_price = price[i+1440]\n",
        "    estimate = eval(price[i:i+1440])\n",
        "    #if (i % 100 == 0):\n",
        "      #print(estimate)\n",
        "    if (estimate > 0):\n",
        "      buying = unit * (estimate / 100)\n",
        "      if (currency > buying * cur_price):\n",
        "        currency = currency - buying * cur_price\n",
        "        share = share + buying\n",
        "      else:\n",
        "        share = share + currency / cur_price\n",
        "        currency = 0\n",
        "    elif (estimate < 0):\n",
        "      selling = -unit * (estimate / 100)\n",
        "      if (share > selling):\n",
        "        share = share - selling\n",
        "        currency = currency + selling * cur_price\n",
        "      else:\n",
        "        currency = currency + share * cur_price\n",
        "        share = 0\n",
        "    result.append(currency + share * cur_price)\n",
        "    bitcoin.append(init_share * cur_price)\n",
        "    if (i % 10000 == 0):\n",
        "      print(currency)\n",
        "      print(share)\n",
        "  plt.plot(result)\n",
        "  plt.plot(bitcoin)\n",
        "  return currency + share * price[period - 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hj2BpwcejGti",
        "colab_type": "code",
        "outputId": "c96baef8-c7c1-446d-86d1-3641fd7eb7af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34289
        }
      },
      "cell_type": "code",
      "source": [
        "simulate(70000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "0\n",
            "0\n",
            "10.157098549815501\n",
            "2739.9502799999927\n",
            "6.928200313310433\n",
            "212.27409000000006\n",
            "9.781229436564729\n",
            "241.35821666666436\n",
            "9.764368106884756\n",
            "0\n",
            "9.986641076074891\n",
            "348.72521333333333\n",
            "9.598373339169314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  10000.0,\n",
              "  9999.999999999998,\n",
              "  9999.999459999997,\n",
              "  10000.006299999997,\n",
              "  10000.00553333333,\n",
              "  10000.00163333333,\n",
              "  9999.99743333333,\n",
              "  9999.991783333331,\n",
              "  9999.984209999999,\n",
              "  9999.973379999998,\n",
              "  10000.009379999998,\n",
              "  10000.009379999998,\n",
              "  10000.009379999998,\n",
              "  10000.007599999999,\n",
              "  9999.935146666665,\n",
              "  9999.935146666665,\n",
              "  9999.932786666664,\n",
              "  9999.932786666663,\n",
              "  9999.932786666663,\n",
              "  9999.93619333333,\n",
              "  9999.93619333333,\n",
              "  9999.93619333333,\n",
              "  9999.936193333328,\n",
              "  10000.000066666662,\n",
              "  10000.087626666662,\n",
              "  10000.087626666662,\n",
              "  10000.11173333333,\n",
              "  10000.11173333333,\n",
              "  10000.11173333333,\n",
              "  10000.111733333328,\n",
              "  10000.133133333327,\n",
              "  10000.15161666666,\n",
              "  10000.15161666666,\n",
              "  10000.15161666666,\n",
              "  10001.298083333328,\n",
              "  10002.176933333327,\n",
              "  10002.176933333327,\n",
              "  10002.176933333325,\n",
              "  10000.94162666666,\n",
              "  10000.954236666661,\n",
              "  10000.954236666661,\n",
              "  10000.958499999995,\n",
              "  10000.958499999995,\n",
              "  10000.958499999995,\n",
              "  10000.958499999995,\n",
              "  10000.958499999995,\n",
              "  10000.958499999995,\n",
              "  10000.958499999995,\n",
              "  10001.370659999995,\n",
              "  10002.212153333328,\n",
              "  10001.847219999994,\n",
              "  10002.160633333327,\n",
              "  10002.212153333328,\n",
              "  10002.139506666661,\n",
              "  10002.139506666661,\n",
              "  10002.20330666666,\n",
              "  10004.355493333329,\n",
              "  10002.717959999996,\n",
              "  10003.484193333328,\n",
              "  10003.509473333328,\n",
              "  10003.509473333328,\n",
              "  10003.509473333328,\n",
              "  10003.50947333333,\n",
              "  10003.50947333333,\n",
              "  10002.335939999997,\n",
              "  10002.692046666663,\n",
              "  10004.31071333333,\n",
              "  10002.97531333333,\n",
              "  10003.104166666662,\n",
              "  10003.14423333333,\n",
              "  10004.144886666663,\n",
              "  10004.144886666663,\n",
              "  10003.155486666663,\n",
              "  10003.12487333333,\n",
              "  10003.117326666663,\n",
              "  10003.790646666663,\n",
              "  10003.56331333333,\n",
              "  10003.706513333329,\n",
              "  10003.706513333329,\n",
              "  10003.706513333329,\n",
              "  10003.706513333327,\n",
              "  10003.706513333327,\n",
              "  10003.706513333327,\n",
              "  10003.706513333327,\n",
              "  10003.706513333327,\n",
              "  10003.706513333327,\n",
              "  10003.880353333328,\n",
              "  10003.704923333327,\n",
              "  10004.095503333328,\n",
              "  10003.594503333328,\n",
              "  10004.089893333326,\n",
              "  10004.100093333327,\n",
              "  10004.100093333327,\n",
              "  10004.100093333327,\n",
              "  10004.185093333328,\n",
              "  10004.103493333327,\n",
              "  10004.865093333327,\n",
              "  10004.793693333328,\n",
              "  10004.035493333327,\n",
              "  10004.045693333328,\n",
              "  10004.865463333328,\n",
              "  10004.685543333328,\n",
              "  10004.803183333328,\n",
              "  10004.858543333328,\n",
              "  10004.858543333328,\n",
              "  10004.858543333328,\n",
              "  10004.858543333328,\n",
              "  10004.376943333327,\n",
              "  10004.215263333328,\n",
              "  10004.858543333328,\n",
              "  10004.858543333328,\n",
              "  10004.858543333328,\n",
              "  10004.858543333328,\n",
              "  10004.290943333328,\n",
              "  10004.290943333328,\n",
              "  10004.211823333328,\n",
              "  10003.382783333327,\n",
              "  10003.375903333328,\n",
              "  10003.375903333326,\n",
              "  10003.375903333326,\n",
              "  10003.375903333326,\n",
              "  10003.375903333324,\n",
              "  10004.151823333325,\n",
              "  10004.151823333325,\n",
              "  10004.209123333323,\n",
              "  10004.209123333323,\n",
              "  10004.189223333322,\n",
              "  10003.634796666656,\n",
              "  10003.668183333324,\n",
              "  10004.227553333323,\n",
              "  10004.14021999999,\n",
              "  10004.140219999988,\n",
              "  10004.331739999987,\n",
              "  10005.194699999987,\n",
              "  10005.194699999987,\n",
              "  10005.189783333319,\n",
              "  10005.189783333319,\n",
              "  10004.801423333318,\n",
              "  10004.801423333318,\n",
              "  10004.774906666651,\n",
              "  10004.764039999984,\n",
              "  10004.764039999985,\n",
              "  10004.764039999985,\n",
              "  10004.764039999985,\n",
              "  10004.764039999985,\n",
              "  10005.110789999986,\n",
              "  10005.110789999986,\n",
              "  10005.306399999985,\n",
              "  10005.306399999987,\n",
              "  10005.047599999985,\n",
              "  10005.302399999986,\n",
              "  10005.308996666652,\n",
              "  10005.308996666652,\n",
              "  10005.308996666652,\n",
              "  10005.181949999986,\n",
              "  10005.195449999985,\n",
              "  10005.31127666665,\n",
              "  10005.31127666665,\n",
              "  10005.181253333318,\n",
              "  10005.311846666651,\n",
              "  10005.291036666651,\n",
              "  10004.406269999983,\n",
              "  10003.860529999984,\n",
              "  10004.404149999984,\n",
              "  10005.341673333318,\n",
              "  10005.334453333318,\n",
              "  10005.334453333318,\n",
              "  10005.33445333332,\n",
              "  10005.33445333332,\n",
              "  10005.36381333332,\n",
              "  10005.36381333332,\n",
              "  10005.36381333332,\n",
              "  10005.36381333332,\n",
              "  10005.36381333332,\n",
              "  10005.43014333332,\n",
              "  10005.879713333321,\n",
              "  10005.879713333321,\n",
              "  10005.86497333332,\n",
              "  10005.872343333322,\n",
              "  10005.879713333321,\n",
              "  10007.08839333332,\n",
              "  10007.08839333332,\n",
              "  10007.331603333321,\n",
              "  10007.51585333332,\n",
              "  10007.30270333332,\n",
              "  10007.19325333332,\n",
              "  10007.251466666654,\n",
              "  10007.251466666654,\n",
              "  10007.331289999986,\n",
              "  10007.331289999986,\n",
              "  10008.579773333318,\n",
              "  10008.579773333318,\n",
              "  10008.572629999984,\n",
              "  10008.579719999983,\n",
              "  10008.346409999984,\n",
              "  10008.402809999983,\n",
              "  10008.831639999982,\n",
              "  10007.938626666648,\n",
              "  10007.938626666648,\n",
              "  10008.455679999981,\n",
              "  10008.455679999981,\n",
              "  10008.868806666647,\n",
              "  10008.533396666648,\n",
              "  10008.533396666648,\n",
              "  10008.862903333313,\n",
              "  10008.794153333312,\n",
              "  10008.849623333314,\n",
              "  10008.813163333314,\n",
              "  10008.795293333314,\n",
              "  10008.795293333314,\n",
              "  10008.812743333314,\n",
              "  10008.847523333314,\n",
              "  10008.870496666648,\n",
              "  10008.870496666648,\n",
              "  10009.14105666665,\n",
              "  10009.972973333315,\n",
              "  10010.533633333314,\n",
              "  10010.533633333316,\n",
              "  10010.533633333314,\n",
              "  10010.533633333314,\n",
              "  10010.579683333313,\n",
              "  10010.579683333313,\n",
              "  10010.579683333313,\n",
              "  10010.579683333313,\n",
              "  10010.183076666648,\n",
              "  10010.369626666647,\n",
              "  10010.574449999978,\n",
              "  10010.574449999978,\n",
              "  10010.56975999998,\n",
              "  10010.569759999978,\n",
              "  10010.574376666646,\n",
              "  10011.27306999998,\n",
              "  10011.291376666644,\n",
              "  10011.291376666644,\n",
              "  10011.322433333313,\n",
              "  10011.256683333311,\n",
              "  10011.471516666645,\n",
              "  10011.471516666645,\n",
              "  10011.471516666646,\n",
              "  10011.471516666646,\n",
              "  10011.471516666646,\n",
              "  10011.471516666645,\n",
              "  10011.440236666645,\n",
              "  10011.471516666645,\n",
              "  10011.440236666645,\n",
              "  10010.959306666646,\n",
              "  10011.471516666645,\n",
              "  10011.471516666645,\n",
              "  10011.471516666645,\n",
              "  10011.471516666645,\n",
              "  10012.074336666645,\n",
              "  10012.062426666645,\n",
              "  10012.463396666644,\n",
              "  10011.871866666645,\n",
              "  10012.459426666645,\n",
              "  10012.459426666645,\n",
              "  10012.665866666644,\n",
              "  10012.665866666644,\n",
              "  10012.665866666644,\n",
              "  10012.661896666645,\n",
              "  10012.665866666644,\n",
              "  10013.134326666644,\n",
              "  10012.705566666646,\n",
              "  10012.681746666645,\n",
              "  10013.217696666647,\n",
              "  10014.197696666646,\n",
              "  10014.213696666646,\n",
              "  10013.969696666645,\n",
              "  10014.217696666647,\n",
              "  10014.341696666646,\n",
              "  10014.660096666646,\n",
              "  10014.660096666646,\n",
              "  10015.124736666647,\n",
              "  10015.128489999981,\n",
              "  10015.128489999981,\n",
              "  10015.167503333316,\n",
              "  10015.397089999982,\n",
              "  10015.397089999982,\n",
              "  10015.406549999983,\n",
              "  10015.676549999982,\n",
              "  10015.696243333314,\n",
              "  10015.696243333316,\n",
              "  10015.696243333314,\n",
              "  10015.702903333315,\n",
              "  10015.733403333315,\n",
              "  10015.919916666648,\n",
              "  10016.238743333313,\n",
              "  10016.466623333314,\n",
              "  10016.466623333314,\n",
              "  10016.344423333316,\n",
              "  10016.316003333315,\n",
              "  10016.329723333316,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.316176666649,\n",
              "  10016.29982666665,\n",
              "  10016.31722666665,\n",
              "  10016.318459999982,\n",
              "  10016.31830666665,\n",
              "  10016.489539999984,\n",
              "  10016.489753333317,\n",
              "  10016.482073333316,\n",
              "  10016.481859999983,\n",
              "  10016.417433333318,\n",
              "  10016.455636666651,\n",
              "  10016.490623333317,\n",
              "  10016.490623333317,\n",
              "  10016.519743333318,\n",
              "  10016.519409999984,\n",
              "  10016.524859999983,\n",
              "  10016.53862666665,\n",
              "  10016.66252666665,\n",
              "  10016.652693333317,\n",
              "  10016.652693333319,\n",
              "  10016.531499999985,\n",
              "  10016.532559999985,\n",
              "  10016.535033333319,\n",
              "  10016.615033333317,\n",
              "  10016.722273333318,\n",
              "  10016.722273333316,\n",
              "  10016.721953333317,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718833333318,\n",
              "  10016.718803333319,\n",
              "  10016.718803333319,\n",
              "  10016.71880333332,\n",
              "  10016.71880333332,\n",
              "  10016.71880333332,\n",
              "  10016.719149999988,\n",
              "  10016.728459999986,\n",
              "  10016.728459999986,\n",
              "  10016.715186666654,\n",
              "  10016.714519999987,\n",
              "  10016.714519999987,\n",
              "  10016.734299999987,\n",
              "  10016.812509999989,\n",
              "  10016.812509999987,\n",
              "  10016.812509999989,\n",
              "  10016.802536666655,\n",
              "  10016.813283333322,\n",
              "  10016.721123333322,\n",
              "  10016.657983333322,\n",
              "  10016.648583333323,\n",
              "  10016.661623333322,\n",
              "  10016.663349999988,\n",
              "  10016.663349999988,\n",
              "  10016.84868333332,\n",
              "  10016.835266666654,\n",
              "  10017.049399999987,\n",
              "  10017.223346666655,\n",
              "  10017.247426666656,\n",
              "  10017.106959999988,\n",
              "  10017.038733333322,\n",
              "  10017.247426666656,\n",
              "  10017.247426666654,\n",
              "  10017.058693333322,\n",
              "  10017.245526666655,\n",
              "  10017.245526666655,\n",
              "  10017.245526666653,\n",
              "  10017.24365333332,\n",
              "  10017.245526666653,\n",
              "  10017.245526666653,\n",
              "  10017.089846666653,\n",
              "  10017.425346666654,\n",
              "  10017.084439999988,\n",
              "  10017.096993333322,\n",
              "  10016.869239999987,\n",
              "  10016.85505333332,\n",
              "  10016.711279999987,\n",
              "  10016.820479999988,\n",
              "  10016.803146666653,\n",
              "  10017.053293333322,\n",
              "  10016.831466666654,\n",
              "  10017.374306666654,\n",
              "  10017.374306666654,\n",
              "  10017.534306666654,\n",
              "  10017.373146666656,\n",
              "  10017.529146666655,\n",
              "  10017.527606666656,\n",
              "  10017.390806666655,\n",
              "  10017.348246666656,\n",
              "  10017.380166666655,\n",
              "  10017.380166666655,\n",
              "  10017.380166666655,\n",
              "  10017.334566666656,\n",
              "  10017.378646666655,\n",
              "  10017.380166666655,\n",
              "  10017.380166666655,\n",
              "  10017.380166666655,\n",
              "  10017.480486666655,\n",
              "  10017.477446666655,\n",
              "  10017.480486666655,\n",
              "  10017.532166666655,\n",
              "  10017.682166666656,\n",
              "  10017.682166666655,\n",
              "  10017.824833333321,\n",
              "  10017.824833333321,\n",
              "  10017.854606666655,\n",
              "  10017.854606666653,\n",
              "  10017.949246666654,\n",
              "  10017.862246666655,\n",
              "  10017.942746666655,\n",
              "  10017.811166666654,\n",
              "  10018.015566666654,\n",
              "  10018.014686666656,\n",
              "  10018.011513333322,\n",
              "  10018.02187333332,\n",
              "  10018.02187333332,\n",
              "  10017.845806666654,\n",
              "  10017.844646666654,\n",
              "  10017.815679999989,\n",
              "  10017.95673333332,\n",
              "  10017.940413333321,\n",
              "  10017.938013333322,\n",
              "  10017.937666666656,\n",
              "  10017.93795999999,\n",
              "  10017.93795999999,\n",
              "  10017.93795999999,\n",
              "  10017.93795999999,\n",
              "  10017.939453333323,\n",
              "  10017.964626666657,\n",
              "  10017.965593333323,\n",
              "  10017.974086666656,\n",
              "  10017.973933333322,\n",
              "  10017.973933333322,\n",
              "  10017.968493333323,\n",
              "  10017.973933333322,\n",
              "  10017.973933333322,\n",
              "  10017.973933333322,\n",
              "  10017.974159999989,\n",
              "  10017.979826666655,\n",
              "  10017.985493333323,\n",
              "  10018.005439999988,\n",
              "  10018.008146666654,\n",
              "  10018.013426666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011906666654,\n",
              "  10018.011786666655,\n",
              "  10018.010406666655,\n",
              "  10018.013243333322,\n",
              "  10018.014549999987,\n",
              "  10018.03643333332,\n",
              "  10018.03643333332,\n",
              "  10018.086699999987,\n",
              "  10018.08128333332,\n",
              "  10018.087999999987,\n",
              "  10018.144549999988,\n",
              "  10018.219283333321,\n",
              "  10018.219426666656,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214836666655,\n",
              "  10018.214956666656,\n",
              "  10018.220956666655,\n",
              "  10018.239586666656,\n",
              "  10018.239826666655,\n",
              "  10018.239946666656,\n",
              "  10018.201426666656,\n",
              "  10018.179626666655,\n",
              "  10018.221926666656,\n",
              "  10018.232526666656,\n",
              "  10018.232446666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.217406666656,\n",
              "  10018.213356666654,\n",
              "  10018.207056666655,\n",
              "  10018.183746666657,\n",
              "  10018.182646666655,\n",
              "  10018.178213333324,\n",
              "  10018.181106666656,\n",
              "  10018.187226666656,\n",
              "  10018.536386666656,\n",
              "  10018.433883333322,\n",
              "  10018.468549999989,\n",
              "  10018.401389999988,\n",
              "  10018.401389999988,\n",
              "  10018.55946999999,\n",
              "  10018.843203333323,\n",
              "  10018.857869999989,\n",
              "  10018.857869999989,\n",
              "  10018.91011999999,\n",
              "  10019.566453333322,\n",
              "  10019.566453333324,\n",
              "  10019.568246666655,\n",
              "  10019.568246666655,\n",
              "  10019.597373333321,\n",
              "  10019.731013333321,\n",
              "  10019.86807999999,\n",
              "  10020.647853333323,\n",
              "  10020.495886666657,\n",
              "  10020.425523333322,\n",
              "  10020.515803333323,\n",
              "  10020.490683333323,\n",
              "  10020.49068333332,\n",
              "  10020.434299999988,\n",
              "  10020.41812999999,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.418086666656,\n",
              "  10020.417306666655,\n",
              "  10020.417246666655,\n",
              "  10020.417246666657,\n",
              "  10020.332313333323,\n",
              "  10020.446063333324,\n",
              "  10020.341023333323,\n",
              "  10020.422203333323,\n",
              "  10020.385283333324,\n",
              "  10020.385283333324,\n",
              "  10020.385283333324,\n",
              "  10020.343596666657,\n",
              "  10020.285316666657,\n",
              "  10020.184576666656,\n",
              "  10020.184576666656,\n",
              "  10020.218059999988,\n",
              "  10020.126726666655,\n",
              "  10019.73312999999,\n",
              "  10019.082689999988,\n",
              "  10018.781999999988,\n",
              "  10018.671799999987,\n",
              "  10018.08380333332,\n",
              "  10017.87770333332,\n",
              "  10019.978356666654,\n",
              "  10017.878076666653,\n",
              "  10018.936926666653,\n",
              "  10018.564979999986,\n",
              "  10019.152733333322,\n",
              "  10018.673319999989,\n",
              "  10017.35927999999,\n",
              "  10016.345446666655,\n",
              "  10015.67127999999,\n",
              "  10015.233146666655,\n",
              "  10014.64181333332,\n",
              "  10016.518506666656,\n",
              "  10016.48633999999,\n",
              "  10015.800273333323,\n",
              "  10016.51298999999,\n",
              "  10016.50934999999,\n",
              "  10016.46787999999,\n",
              "  10016.52247999999,\n",
              "  10016.518449999989,\n",
              "  10017.760576666657,\n",
              "  10014.897156666657,\n",
              "  10014.897156666657,\n",
              "  10015.910706666657,\n",
              "  10015.910706666657,\n",
              "  10016.609756666656,\n",
              "  10016.609756666656,\n",
              "  10017.493596666656,\n",
              "  10019.800996666656,\n",
              "  10020.227263333323,\n",
              "  10020.26432999999,\n",
              "  10022.561769999991,\n",
              "  10022.543396666659,\n",
              "  10021.667176666659,\n",
              "  10022.078496666658,\n",
              "  10022.055996666657,\n",
              "  10022.042556666656,\n",
              "  10021.551956666657,\n",
              "  10020.388676666656,\n",
              "  10019.889216666657,\n",
              "  10019.356816666657,\n",
              "  10019.453176666659,\n",
              "  10019.235176666658,\n",
              "  10019.039876666659,\n",
              "  10019.018276666658,\n",
              "  10018.996776666658,\n",
              "  10018.970976666658,\n",
              "  10018.979576666658,\n",
              "  10019.013976666658,\n",
              "  10018.953776666658,\n",
              "  10018.354576666658,\n",
              "  10017.759656666658,\n",
              "  10017.626976666657,\n",
              "  10016.471376666657,\n",
              "  10016.009136666658,\n",
              "  10015.962056666658,\n",
              "  10015.768106666657,\n",
              "  10015.559786666658,\n",
              "  10015.427686666657,\n",
              "  10015.868686666656,\n",
              "  10014.618586666656,\n",
              "  10014.961306666657,\n",
              "  10014.542823333322,\n",
              "  10012.73372999999,\n",
              "  10013.915529999991,\n",
              "  10014.182863333324,\n",
              "  10014.226676666658,\n",
              "  10016.422569999992,\n",
              "  10016.42256999999,\n",
              "  10017.017569999989,\n",
              "  10017.017569999989,\n",
              "  10020.116556666657,\n",
              "  10020.43724999999,\n",
              "  10020.425796666657,\n",
              "  10020.425796666657,\n",
              "  10022.12088999999,\n",
              "  10022.06934999999,\n",
              "  10022.126416666657,\n",
              "  10023.26774999999,\n",
              "  10023.262043333323,\n",
              "  10024.632529999992,\n",
              "  10024.337863333325,\n",
              "  ...],\n",
              " [10000.0,\n",
              "  10014.492339082597,\n",
              "  9990.37022205696,\n",
              "  9984.840250564916,\n",
              "  9990.274877720889,\n",
              "  9991.132976745519,\n",
              "  9997.330358590048,\n",
              "  9973.970996252967,\n",
              "  9990.17953338482,\n",
              "  9985.126283573125,\n",
              "  9984.840250564916,\n",
              "  9984.840250564916,\n",
              "  9962.148298580323,\n",
              "  9966.248105031322,\n",
              "  9968.345680424854,\n",
              "  9973.017552892272,\n",
              "  9972.922208556201,\n",
              "  9972.922208556201,\n",
              "  9983.98215154029,\n",
              "  9989.988844712681,\n",
              "  9989.988844712681,\n",
              "  9990.08418904875,\n",
              "  9990.08418904875,\n",
              "  9990.08418904875,\n",
              "  9990.08418904875,\n",
              "  9990.08418904875,\n",
              "  9990.08418904875,\n",
              "  9987.700580647008,\n",
              "  9987.700580647008,\n",
              "  9990.08418904875,\n",
              "  9992.372453114423,\n",
              "  10011.059942984088,\n",
              "  9996.8536369097,\n",
              "  9996.94898124577,\n",
              "  9996.94898124577,\n",
              "  9992.277108778353,\n",
              "  9999.427933983583,\n",
              "  9992.181764442284,\n",
              "  9992.086420106214,\n",
              "  10010.773909975878,\n",
              "  10010.773909975878,\n",
              "  9992.181764442284,\n",
              "  9959.28796849823,\n",
              "  9959.28796849823,\n",
              "  9959.28796849823,\n",
              "  9959.28796849823,\n",
              "  9959.28796849823,\n",
              "  9958.429869473604,\n",
              "  9965.676039014903,\n",
              "  9965.199317334555,\n",
              "  9963.4831192853,\n",
              "  9962.052954244253,\n",
              "  9960.62278920321,\n",
              "  9959.097279826092,\n",
              "  9957.285737440767,\n",
              "  9962.434331588534,\n",
              "  9962.434331588534,\n",
              "  9962.434331588534,\n",
              "  9962.243642916392,\n",
              "  9954.997473375093,\n",
              "  9954.997473375093,\n",
              "  9954.806784702954,\n",
              "  9954.806784702954,\n",
              "  9954.806784702954,\n",
              "  9954.997473375093,\n",
              "  9954.997473375093,\n",
              "  9954.997473375093,\n",
              "  9954.997473375093,\n",
              "  9957.476426112906,\n",
              "  9960.62278920321,\n",
              "  9960.62278920321,\n",
              "  9961.385543891765,\n",
              "  9961.385543891765,\n",
              "  9961.385543891765,\n",
              "  9961.385543891765,\n",
              "  9961.957609908184,\n",
              "  9962.434331588534,\n",
              "  9962.434331588534,\n",
              "  9962.434331588534,\n",
              "  9990.08418904875,\n",
              "  10010.773909975878,\n",
              "  10010.773909975878,\n",
              "  10010.773909975878,\n",
              "  9982.551986499242,\n",
              "  9982.838019507451,\n",
              "  9982.838019507451,\n",
              "  9982.933363843522,\n",
              "  9982.933363843522,\n",
              "  9982.933363843522,\n",
              "  9982.933363843522,\n",
              "  9982.933363843522,\n",
              "  9982.933363843522,\n",
              "  9982.933363843522,\n",
              "  9992.086420106214,\n",
              "  10010.773909975878,\n",
              "  10002.669641409952,\n",
              "  10009.62977794304,\n",
              "  10010.773909975878,\n",
              "  10009.153056262694,\n",
              "  10009.153056262694,\n",
              "  10010.58322130374,\n",
              "  10058.827455355016,\n",
              "  10022.119885968175,\n",
              "  10039.377210796794,\n",
              "  10039.949276813211,\n",
              "  10039.949276813211,\n",
              "  10039.949276813211,\n",
              "  10039.949276813211,\n",
              "  10039.949276813211,\n",
              "  10012.299419352994,\n",
              "  10020.68972092713,\n",
              "  10058.827455355016,\n",
              "  10027.36382445201,\n",
              "  10030.41484320624,\n",
              "  10031.368286566936,\n",
              "  10055.299714920437,\n",
              "  10055.299714920437,\n",
              "  10030.986909222658,\n",
              "  10030.2241545341,\n",
              "  10030.033465861961,\n",
              "  10047.29079069058,\n",
              "  10041.379441854258,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10045.193215297046,\n",
              "  10050.24646510874,\n",
              "  10045.193215297046,\n",
              "  10056.443846953272,\n",
              "  10042.142196542814,\n",
              "  10056.157813945063,\n",
              "  10056.443846953272,\n",
              "  10056.443846953272,\n",
              "  10056.443846953272,\n",
              "  10058.827455355016,\n",
              "  10056.539191289343,\n",
              "  10077.896322568959,\n",
              "  10075.894091511494,\n",
              "  10054.632304567947,\n",
              "  10054.918337576157,\n",
              "  10077.70563389682,\n",
              "  10072.747728421195,\n",
              "  10075.989435847563,\n",
              "  10077.51494522468,\n",
              "  10077.51494522468,\n",
              "  10077.51494522468,\n",
              "  10077.51494522468,\n",
              "  10064.16673817492,\n",
              "  10059.685554379643,\n",
              "  10077.51494522468,\n",
              "  10077.51494522468,\n",
              "  10077.51494522468,\n",
              "  10077.51494522468,\n",
              "  10061.783129773175,\n",
              "  10061.783129773175,\n",
              "  10059.590210043572,\n",
              "  10036.612225050772,\n",
              "  10036.421536378633,\n",
              "  10036.421536378633,\n",
              "  10036.421536378633,\n",
              "  10036.421536378633,\n",
              "  10036.421536378633,\n",
              "  10056.634535625411,\n",
              "  10056.634535625411,\n",
              "  10058.064700666459,\n",
              "  10058.064700666459,\n",
              "  10057.587978986108,\n",
              "  10044.621149280627,\n",
              "  10045.383903969185,\n",
              "  10057.87401199432,\n",
              "  10055.967125272924,\n",
              "  10055.967125272924,\n",
              "  10059.97158738785,\n",
              "  10077.51494522468,\n",
              "  10077.51494522468,\n",
              "  10077.41960088861,\n",
              "  10077.41960088861,\n",
              "  10070.173431347312,\n",
              "  10070.173431347312,\n",
              "  10069.696709666963,\n",
              "  10069.506020994822,\n",
              "  10069.506020994822,\n",
              "  10069.506020994822,\n",
              "  10069.506020994822,\n",
              "  10069.506020994822,\n",
              "  10074.940648150798,\n",
              "  10074.940648150798,\n",
              "  10077.896322568959,\n",
              "  10077.896322568959,\n",
              "  10074.08254912617,\n",
              "  10077.80097823289,\n",
              "  10077.896322568959,\n",
              "  10077.896322568959,\n",
              "  10077.896322568959,\n",
              "  10076.084780183633,\n",
              "  10076.275468855772,\n",
              "  10077.896322568959,\n",
              "  10077.896322568959,\n",
              "  10076.084780183633,\n",
              "  10077.896322568959,\n",
              "  10077.61028956075,\n",
              "  10065.501558879896,\n",
              "  10058.064700666459,\n",
              "  10065.406214543826,\n",
              "  10077.896322568959,\n",
              "  10077.80097823289,\n",
              "  10077.80097823289,\n",
              "  10077.80097823289,\n",
              "  10077.80097823289,\n",
              "  10078.182355577168,\n",
              "  10078.182355577168,\n",
              "  10078.182355577168,\n",
              "  10078.182355577168,\n",
              "  10078.182355577168,\n",
              "  10079.040454601794,\n",
              "  10084.856459102048,\n",
              "  10084.856459102048,\n",
              "  10084.665770429909,\n",
              "  10084.761114765979,\n",
              "  10084.856459102048,\n",
              "  10100.49293021748,\n",
              "  10100.49293021748,\n",
              "  10103.639293307782,\n",
              "  10106.022901709526,\n",
              "  10103.257915963504,\n",
              "  10101.827750922457,\n",
              "  10102.590505611015,\n",
              "  10102.590505611015,\n",
              "  10103.639293307782,\n",
              "  10103.639293307782,\n",
              "  10120.133863447843,\n",
              "  10120.133863447843,\n",
              "  10120.038519111773,\n",
              "  10120.133863447843,\n",
              "  10116.987500357542,\n",
              "  10117.750255046101,\n",
              "  10123.566259546353,\n",
              "  10111.36218452943,\n",
              "  10111.36218452943,\n",
              "  10118.608354070728,\n",
              "  10118.608354070728,\n",
              "  10124.519702907051,\n",
              "  10119.657141767495,\n",
              "  10119.657141767495,\n",
              "  10124.61504724312,\n",
              "  10123.566259546353,\n",
              "  10124.424358570981,\n",
              "  10123.85229255456,\n",
              "  10123.566259546353,\n",
              "  10123.566259546353,\n",
              "  10123.85229255456,\n",
              "  10124.424358570981,\n",
              "  10124.805735915259,\n",
              "  10124.805735915259,\n",
              "  10129.382264046606,\n",
              "  10143.588570120994,\n",
              "  10153.313692400105,\n",
              "  10153.313692400105,\n",
              "  10153.313692400105,\n",
              "  10153.313692400105,\n",
              "  10154.171791424731,\n",
              "  10154.171791424731,\n",
              "  10154.171791424731,\n",
              "  10154.171791424731,\n",
              "  10146.353555867016,\n",
              "  10150.071984973732,\n",
              "  10154.171791424731,\n",
              "  10154.171791424731,\n",
              "  10154.076447088662,\n",
              "  10154.076447088662,\n",
              "  10154.171791424731,\n",
              "  10168.664130507328,\n",
              "  10169.045507851606,\n",
              "  10169.045507851606,\n",
              "  10169.712918204095,\n",
              "  10168.28275316305,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10172.287215277978,\n",
              "  10173.049969966536,\n",
              "  10172.287215277978,\n",
              "  10160.559861941403,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10173.049969966536,\n",
              "  10187.637653385202,\n",
              "  10187.351620376992,\n",
              "  10196.981398320033,\n",
              "  10182.775092245645,\n",
              "  10196.886053983964,\n",
              "  10196.886053983964,\n",
              "  10201.84395945959,\n",
              "  10201.84395945959,\n",
              "  10201.84395945959,\n",
              "  10201.748615123519,\n",
              "  10201.84395945959,\n",
              "  10213.094591115816,\n",
              "  10202.797402820286,\n",
              "  10202.225336803867,\n",
              "  10215.09682217328,\n",
              "  10238.45618451036,\n",
              "  10238.83756185464,\n",
              "  10233.021557354386,\n",
              "  10238.93290619071,\n",
              "  10241.888580608871,\n",
              "  10249.516127494448,\n",
              "  10249.516127494448,\n",
              "  10261.052792158884,\n",
              "  10261.148136494952,\n",
              "  10261.148136494952,\n",
              "  10262.19692419172,\n",
              "  10268.58499470839,\n",
              "  10268.58499470839,\n",
              "  10268.8710277166,\n",
              "  10277.452017962874,\n",
              "  10278.119428315362,\n",
              "  10278.119428315362,\n",
              "  10278.119428315362,\n",
              "  10278.405461323571,\n",
              "  10279.835626364616,\n",
              "  10289.465404307659,\n",
              "  10308.152894177323,\n",
              "  10323.598676620617,\n",
              "  10323.598676620617,\n",
              "  10310.155125234785,\n",
              "  10305.48325276737,\n",
              "  10309.487714882298,\n",
              "  10297.378984201445,\n",
              "  10309.487714882298,\n",
              "  10309.297026210159,\n",
              "  10309.297026210159,\n",
              "  10323.312643612408,\n",
              "  10322.93126626813,\n",
              "  10323.598676620617,\n",
              "  10323.598676620617,\n",
              "  10335.326029957192,\n",
              "  10344.765119228094,\n",
              "  10363.929330778106,\n",
              "  10363.929330778106,\n",
              "  10384.809740377374,\n",
              "  10382.998197992049,\n",
              "  10382.998197992049,\n",
              "  10326.840384046985,\n",
              "  10336.279473317887,\n",
              "  10335.898095973609,\n",
              "  10335.70740730147,\n",
              "  10314.540964693993,\n",
              "  10306.532040464137,\n",
              "  10296.330196504678,\n",
              "  10277.928739643223,\n",
              "  10297.283639865374,\n",
              "  10314.540964693993,\n",
              "  10328.270549088033,\n",
              "  10343.334954187047,\n",
              "  10335.898095973609,\n",
              "  10325.79159635022,\n",
              "  10317.496639112156,\n",
              "  10317.496639112156,\n",
              "  10309.773747890507,\n",
              "  10302.33688967707,\n",
              "  10311.203912931553,\n",
              "  10324.742808653455,\n",
              "  10264.199155249184,\n",
              "  10278.214772651432,\n",
              "  10284.316810159895,\n",
              "  10297.378984201445,\n",
              "  10296.520885176818,\n",
              "  10295.18606447184,\n",
              "  10305.10187542309,\n",
              "  10308.915648865881,\n",
              "  10309.487714882298,\n",
              "  10344.860463564162,\n",
              "  10335.039996948983,\n",
              "  10342.66754383456,\n",
              "  10320.929035210664,\n",
              "  10318.831459817131,\n",
              "  10314.254931685784,\n",
              "  10313.015455316878,\n",
              "  10305.95997444772,\n",
              "  10303.290333037769,\n",
              "  10301.669479324582,\n",
              "  10321.215068218873,\n",
              "  10326.07762935843,\n",
              "  10325.79159635022,\n",
              "  10335.6120629654,\n",
              "  10342.953576842769,\n",
              "  10349.1509586873,\n",
              "  10344.955807900233,\n",
              "  10330.749501825845,\n",
              "  10344.383741883814,\n",
              "  10339.425836408189,\n",
              "  10363.929330778106,\n",
              "  10353.727486818647,\n",
              "  10363.929330778106,\n",
              "  10363.929330778106,\n",
              "  10373.082387040798,\n",
              "  10382.998197992049,\n",
              "  10382.998197992049,\n",
              "  10384.809740377374,\n",
              "  10344.860463564162,\n",
              "  10359.16211397462,\n",
              "  10363.738642105967,\n",
              "  10363.738642105967,\n",
              "  10363.547953433828,\n",
              "  10363.547953433828,\n",
              "  10363.738642105967,\n",
              "  10363.643297769897,\n",
              "  10363.738642105967,\n",
              "  10363.643297769897,\n",
              "  10361.641066712433,\n",
              "  10357.922637605712,\n",
              "  10359.734179991037,\n",
              "  10354.776274515412,\n",
              "  10359.35280264676,\n",
              "  10359.35280264676,\n",
              "  10359.829524327108,\n",
              "  10359.829524327108,\n",
              "  10363.833986442036,\n",
              "  10363.833986442036,\n",
              "  10363.833986442036,\n",
              "  10363.833986442036,\n",
              "  10363.833986442036,\n",
              "  10363.833986442036,\n",
              "  10368.505858909453,\n",
              "  10368.410514573383,\n",
              "  10368.696547581592,\n",
              "  10373.177731376869,\n",
              "  10384.809740377374,\n",
              "  10390.911777885834,\n",
              "  10390.911777885834,\n",
              "  10392.53263159902,\n",
              "  10392.53263159902,\n",
              "  10392.437287262952,\n",
              "  10392.53263159902,\n",
              "  10397.013815394297,\n",
              "  10392.341942926882,\n",
              "  10392.81866460723,\n",
              "  10392.81866460723,\n",
              "  10392.81866460723,\n",
              "  10391.388499566185,\n",
              "  10392.53263159902,\n",
              "  10397.013815394297,\n",
              "  10404.164640599527,\n",
              "  10404.164640599527,\n",
              "  10394.153485312207,\n",
              "  10392.627975935091,\n",
              "  10404.641362279874,\n",
              "  10404.641362279874,\n",
              "  10393.962796640068,\n",
              "  10386.907315770908,\n",
              "  10395.297617345042,\n",
              "  10403.592574583108,\n",
              "  10402.067065205993,\n",
              "  10395.202273008972,\n",
              "  10376.896160483586,\n",
              "  10372.60566536045,\n",
              "  10382.80750931991,\n",
              "  10381.663377287072,\n",
              "  10389.290924172652,\n",
              "  10388.90954682837,\n",
              "  10400.636900164945,\n",
              "  10402.067065205993,\n",
              "  10402.067065205993,\n",
              "  10402.067065205993,\n",
              "  10402.067065205993,\n",
              "  10404.832050952014,\n",
              "  10404.832050952014,\n",
              "  10405.499461304502,\n",
              "  10411.410810140826,\n",
              "  10411.124777132616,\n",
              "  10410.934088460477,\n",
              "  10420.849899411727,\n",
              "  10431.623809387604,\n",
              "  10431.623809387604,\n",
              "  10430.384333018697,\n",
              "  10431.623809387604,\n",
              "  10431.623809387604,\n",
              "  10439.8234222896,\n",
              "  10439.251356273182,\n",
              "  10440.204799633879,\n",
              "  10440.109455297808,\n",
              "  10440.204799633879,\n",
              "  10439.251356273182,\n",
              "  10435.056205486115,\n",
              "  10434.960861150044,\n",
              "  10440.109455297808,\n",
              "  10449.73923324085,\n",
              "  10449.73923324085,\n",
              "  10459.273666847821,\n",
              "  10459.273666847821,\n",
              "  10468.808100454793,\n",
              "  10476.054269996092,\n",
              "  10476.054269996092,\n",
              "  10476.054269996092,\n",
              "  10476.054269996092,\n",
              "  10468.808100454793,\n",
              "  10468.808100454793,\n",
              "  10474.338071946837,\n",
              "  10468.808100454793,\n",
              "  10467.282591077677,\n",
              "  10466.233803380912,\n",
              "  10440.490832642088,\n",
              "  10444.018573076668,\n",
              "  10361.641066712433,\n",
              "  10326.745039710917,\n",
              "  10325.50556334201,\n",
              "  10233.688967706874,\n",
              "  10225.20332179667,\n",
              "  10173.240658638675,\n",
              "  10200.890516098892,\n",
              "  10201.84395945959,\n",
              "  10201.748615123519,\n",
              "  10290.800225012634,\n",
              "  10290.895569348702,\n",
              "  10287.463173250195,\n",
              "  10287.367828914124,\n",
              "  10258.573839421071,\n",
              "  10273.542900184015,\n",
              "  10285.746975200938,\n",
              "  10285.746975200938,\n",
              "  10294.900031463632,\n",
              "  10294.804687127562,\n",
              "  10296.234852168609,\n",
              "  10299.571903931048,\n",
              "  10329.60536979301,\n",
              "  10327.221761391267,\n",
              "  10327.221761391267,\n",
              "  10294.518654119353,\n",
              "  10294.804687127562,\n",
              "  10295.47209748005,\n",
              "  10318.354738136783,\n",
              "  10354.871618851483,\n",
              "  10354.871618851483,\n",
              "  10354.585585843273,\n",
              "  10339.711869416398,\n",
              "  10339.61652508033,\n",
              "  10344.574430555955,\n",
              "  10354.490241507205,\n",
              "  10350.104402047997,\n",
              "  10350.104402047997,\n",
              "  10365.645528827361,\n",
              "  10345.241840908442,\n",
              "  10361.641066712433,\n",
              "  10361.069000696016,\n",
              "  10344.860463564162,\n",
              "  10365.645528827361,\n",
              "  10365.645528827361,\n",
              "  10354.204208498995,\n",
              "  10344.288397547745,\n",
              "  10337.709638358934,\n",
              "  10337.709638358934,\n",
              "  10350.199746384067,\n",
              "  10344.955807900233,\n",
              "  10355.92040654825,\n",
              "  10355.25299619576,\n",
              "  10354.490241507205,\n",
              "  10345.718562588789,\n",
              "  10346.862694621628,\n",
              "  10346.862694621628,\n",
              "  10344.860463564162,\n",
              "  10344.860463564162,\n",
              "  10344.765119228094,\n",
              "  10344.765119228094,\n",
              "  10344.765119228094,\n",
              "  10344.765119228094,\n",
              "  10344.765119228094,\n",
              "  10344.860463564162,\n",
              "  10346.862694621628,\n",
              "  10346.862694621628,\n",
              "  10344.765119228094,\n",
              "  10344.669774892023,\n",
              "  10344.669774892023,\n",
              "  10346.862694621628,\n",
              "  10354.394897171134,\n",
              "  10354.394897171134,\n",
              "  10354.394897171134,\n",
              "  10353.632142482578,\n",
              "  10354.394897171134,\n",
              "  10348.292859662672,\n",
              "  10344.288397547745,\n",
              "  10343.716331531328,\n",
              "  10344.479086219884,\n",
              "  10344.574430555955,\n",
              "  10344.574430555955,\n",
              "  10354.108864162925,\n",
              "  10353.441453810437,\n",
              "  10363.929330778106,\n",
              "  10372.319632352242,\n",
              "  10373.463764385078,\n",
              "  10366.789660860197,\n",
              "  10363.547953433828,\n",
              "  10373.463764385078,\n",
              "  10373.463764385078,\n",
              "  10364.406052458455,\n",
              "  10373.463764385078,\n",
              "  10373.463764385078,\n",
              "  10373.463764385078,\n",
              "  10373.368420049008,\n",
              "  10373.463764385078,\n",
              "  10373.463764385078,\n",
              "  10365.454840155222,\n",
              "  10382.90285365598,\n",
              "  10364.978118474872,\n",
              "  10365.645528827361,\n",
              "  10353.536798146508,\n",
              "  10352.774043457948,\n",
              "  10344.955807900233,\n",
              "  10350.962501072625,\n",
              "  10350.009057711928,\n",
              "  10363.929330778106,\n",
              "  10351.439222752973,\n",
              "  10382.998197992049,\n",
              "  10382.998197992049,\n",
              "  10392.53263159902,\n",
              "  10382.80750931991,\n",
              "  10392.341942926882,\n",
              "  10392.246598590811,\n",
              "  10383.665608344536,\n",
              "  10380.995966934584,\n",
              "  10382.998197992049,\n",
              "  10382.998197992049,\n",
              "  10382.998197992049,\n",
              "  10380.137867909958,\n",
              "  10382.90285365598,\n",
              "  10382.998197992049,\n",
              "  10382.998197992049,\n",
              "  10382.998197992049,\n",
              "  10389.290924172652,\n",
              "  10389.100235500511,\n",
              "  10389.290924172652,\n",
              "  10392.53263159902,\n",
              "  10402.067065205993,\n",
              "  10402.067065205993,\n",
              "  10411.601498812965,\n",
              "  10411.601498812965,\n",
              "  10413.699074206497,\n",
              "  10413.699074206497,\n",
              "  10421.135932419935,\n",
              "  10413.985107214707,\n",
              "  10421.135932419935,\n",
              "  10408.836513066943,\n",
              "  10429.71692266621,\n",
              "  10429.621578330141,\n",
              "  10429.24020098586,\n",
              "  10430.575021690838,\n",
              "  10430.575021690838,\n",
              "  10404.069296263457,\n",
              "  10403.878607591318,\n",
              "  10398.634669107483,\n",
              "  10427.047281256257,\n",
              "  10423.614885157747,\n",
              "  10423.04281914133,\n",
              "  10422.94747480526,\n",
              "  10423.04281914133,\n",
              "  10423.04281914133,\n",
              "  10423.04281914133,\n",
              "  10423.04281914133,\n",
              "  10423.710229493818,\n",
              "  10434.960861150044,\n",
              "  10435.437582830393,\n",
              "  10440.109455297808,\n",
              "  10440.01411096174,\n",
              "  10440.01411096174,\n",
              "  10435.437582830393,\n",
              "  10440.01411096174,\n",
              "  10440.01411096174,\n",
              "  10440.01411096174,\n",
              "  10440.204799633879,\n",
              "  10444.972016437365,\n",
              "  10449.73923324085,\n",
              "  10466.51983638912,\n",
              "  10469.284822135141,\n",
              "  10476.149614332162,\n",
              "  10468.903444790863,\n",
              "  10472.717218233653,\n",
              "  10439.251356273182,\n",
              "  10455.269204732893,\n",
              "  10475.768236987882,\n",
              "  10475.863581323953,\n",
              "  10476.24495866823,\n",
              "  10476.24495866823,\n",
              "  10476.43564734037,\n",
              "  10468.808100454793,\n",
              "  10468.808100454793,\n",
              "  10468.808100454793,\n",
              "  10468.522067446585,\n",
              "  10468.808100454793,\n",
              "  10487.876967668737,\n",
              "  10537.26533375285,\n",
              "  10583.221303738452,\n",
              "  10592.755737345424,\n",
              "  10678.565639808168,\n",
              "  10688.10007341514,\n",
              "  10740.444113917414,\n",
              "  10772.956532517188,\n",
              "  10740.539458253483,\n",
              "  10763.422098910216,\n",
              "  10716.417341227845,\n",
              "  10704.117921874853,\n",
              "  10690.579026152953,\n",
              "  10677.516852111403,\n",
              "  10679.137705824585,\n",
              "  10678.565639808168,\n",
              "  10678.470295472098,\n",
              "  10659.306083922085,\n",
              "  10659.306083922085,\n",
              "  10659.306083922085,\n",
              "  10654.920244462879,\n",
              "  10678.565639808168,\n",
              "  10698.587950382807,\n",
              "  10698.587950382807,\n",
              "  10716.703374236055,\n",
              "  10678.565639808168,\n",
              "  10678.565639808168,\n",
              "  10710.887369735803,\n",
              "  10710.69668106366,\n",
              "  10706.215497268387,\n",
              "  10688.10007341514,\n",
              "  10688.10007341514,\n",
              "  10703.831888866644,\n",
              "  10706.215497268387,\n",
              "  10710.792025399733,\n",
              "  10707.168940629082,\n",
              "  10707.168940629082,\n",
              "  10678.279606799959,\n",
              "  10677.89822945568,\n",
              "  10675.705309726078,\n",
              "  10677.89822945568,\n",
              "  10678.565639808168,\n",
              "  10688.195417751209,\n",
              "  10688.195417751209,\n",
              "  10710.315303719382,\n",
              "  10707.93169531764,\n",
              "  10710.887369735803,\n",
              "  10735.772241449997,\n",
              "  10772.00308915649,\n",
              "  10772.09843349256,\n",
              "  10764.375542270913,\n",
              "  10773.909975877885,\n",
              "  10814.908040387862,\n",
              "  10821.582143912741,\n",
              "  10868.205524250834,\n",
              "  10868.205524250834,\n",
              "  10864.487095144113,\n",
              "  10863.247618775207,\n",
              "  10863.342963111278,\n",
              "  10863.342963111278,\n",
              "  10845.036850585891,\n",
              "  10843.129963864498,\n",
              "  10829.019002126179,\n",
              "  10826.349360716227,\n",
              "  10820.914733560254,\n",
              "  10801.655177674173,\n",
              "  10812.047710305771,\n",
              "  10812.047710305771,\n",
              "  10774.86341923858,\n",
              "  10773.909975877885,\n",
              "  10774.577386230372,\n",
              "  10774.768074902511,\n",
              "  10774.768074902511,\n",
              "  10726.523840851234,\n",
              "  10773.909975877885,\n",
              "  10773.051876853257,\n",
              "  10764.94760828733,\n",
              "  10726.523840851234,\n",
              "  10792.883498755757,\n",
              "  10782.967687804507,\n",
              "  10772.193777828628,\n",
              "  10783.063032140577,\n",
              "  10783.444409484855,\n",
              "  10792.978843091827,\n",
              "  10812.715120658258,\n",
              "  10812.905809330397,\n",
              "  10813.001153666466,\n",
              "  10782.39562178809,\n",
              "  10761.61055652489,\n",
              "  10801.94121068238,\n",
              "  10812.047710305771,\n",
              "  10811.9523659697,\n",
              "  10758.17816042638,\n",
              "  10758.17816042638,\n",
              "  10810.808233936863,\n",
              "  10787.258182927644,\n",
              "  10839.0301574135,\n",
              "  10840.651011126685,\n",
              "  10838.934813077429,\n",
              "  10838.934813077429,\n",
              "  10825.300573019462,\n",
              "  10820.342667543835,\n",
              "  10816.528894101048,\n",
              "  10793.360220436105,\n",
              "  10831.116577519713,\n",
              "  10784.779230189832,\n",
              "  10820.533356215976,\n",
              "  10819.770601527416,\n",
              "  10819.770601527416,\n",
              "  10805.850328461238,\n",
              "  10821.296110904534,\n",
              "  10806.13636146945,\n",
              "  10804.420163420193,\n",
              "  10764.566230943052,\n",
              "  10800.606389977404,\n",
              "  10817.482337461743,\n",
              "  10817.768370469952,\n",
              "  10812.23839897791,\n",
              "  10817.768370469952,\n",
              "  10821.582143912741,\n",
              "  10717.084751580333,\n",
              "  10711.936157432569,\n",
              "  10685.430432005189,\n",
              "  10685.430432005189,\n",
              "  10716.131308219638,\n",
              "  10716.131308219638,\n",
              "  10717.084751580333,\n",
              "  10716.894062908194,\n",
              "  10717.084751580333,\n",
              "  10697.253129677832,\n",
              "  10695.441587292507,\n",
              "  10658.734017905668,\n",
              "  10613.350113936483,\n",
              "  10569.968441024761,\n",
              "  10630.512094429032,\n",
              "  10630.321405756893,\n",
              "  10628.795896379776,\n",
              "  10630.130717084754,\n",
              "  10631.846915134007,\n",
              "  10631.942259470075,\n",
              "  10631.942259470075,\n",
              "  10616.210444018574,\n",
              "  10564.05709218844,\n",
              "  10553.855248228982,\n",
              "  10526.014702096623,\n",
              "  10525.442636080204,\n",
              "  10509.710820628701,\n",
              "  10496.83933525929,\n",
              "  10486.82817997197,\n",
              "  10468.808100454793,\n",
              "  10468.331378774445,\n",
              "  10466.996558069468,\n",
              "  10467.663968421957,\n",
              "  10468.808100454793,\n",
              "  10526.87280112125,\n",
              "  10511.522363014026,\n",
              "  10516.480268489651,\n",
              "  10507.708589571237,\n",
              "  10507.708589571237,\n",
              "  10526.014702096623,\n",
              "  10556.524889638933,\n",
              "  10558.050399016047,\n",
              "  10558.050399016047,\n",
              "  10563.485026172022,\n",
              "  10631.751570797936,\n",
              "  10631.751570797936,\n",
              "  10631.942259470075,\n",
              "  10631.942259470075,\n",
              "  10635.183966896448,\n",
              "  10650.057683323323,\n",
              "  10665.312777094477,\n",
              "  10754.173698311453,\n",
              "  10735.676897113928,\n",
              "  10726.047119170888,\n",
              "  10740.158080909205,\n",
              "  10735.581552777858,\n",
              "  10735.581552777858,\n",
              "  10716.608029899984,\n",
              "  10707.168940629082,\n",
              "  10707.073596293014,\n",
              "  10707.168940629082,\n",
              "  10704.308610546992,\n",
              "  10704.213266210922,\n",
              "  10678.660984144239,\n",
              "  10697.63450702211,\n",
              "  10697.63450702211,\n",
              "  10720.326459006705,\n",
              "  10704.68998789127,\n",
              "  10697.63450702211,\n",
              "  10710.982714071872,\n",
              "  10705.452742579828,\n",
              "  10665.789498774828,\n",
              "  10696.585719325345,\n",
              "  10685.716465013396,\n",
              "  10688.10007341514,\n",
              "  10688.10007341514,\n",
              "  10686.574564038023,\n",
              "  10686.383875365884,\n",
              "  10686.097842357676,\n",
              "  10686.383875365884,\n",
              "  10683.904922628071,\n",
              "  10683.809578292003,\n",
              "  10683.809578292003,\n",
              "  10640.427905380282,\n",
              "  10683.809578292003,\n",
              "  10654.920244462879,\n",
              "  10673.798423004682,\n",
              "  10666.361564791245,\n",
              "  10666.361564791245,\n",
              "  10666.361564791245,\n",
              "  10659.306083922085,\n",
              "  10650.439060667602,\n",
              "  10636.518787601422,\n",
              "  10636.518787601422,\n",
              "  10640.427905380282,\n",
              "  10630.89347177331,\n",
              "  10592.469704337214,\n",
              "  10534.691036678967,\n",
              "  10510.18754230905,\n",
              "  10501.892585070986,\n",
              "  10461.752619585634,\n",
              "  10448.881134216224,\n",
              "  10569.777752352622,\n",
              "  10459.75038852817,\n",
              "  10511.522363014026,\n",
              "  10494.741759865756,\n",
              "  10519.721975916022,\n",
              "  10500.462420029939,\n",
              "  10449.73923324085,\n",
              "  10412.078220493313,\n",
              "  10388.242136475883,\n",
              "  10373.463764385078,\n",
              "  10354.394897171134,\n",
              "  10412.36425350152,\n",
              "  10411.410810140826,\n",
              "  10391.865221246533,\n",
              "  10411.410810140826,\n",
              "  10411.315465804755,\n",
              "  10410.266678107986,\n",
              "  10411.601498812965,\n",
              "  10411.506154476894,\n",
              "  10440.204799633879,\n",
              "  10375.561339778611,\n",
              "  10375.561339778611,\n",
              "  10397.776570082855,\n",
              "  10397.776570082855,\n",
              "  10412.55494217366,\n",
              "  10412.55494217366,\n",
              "  10430.861054699046,\n",
              "  10478.342534061765,\n",
              "  10487.11421298018,\n",
              "  10487.876967668737,\n",
              "  10535.358447031454,\n",
              "  10534.977069687176,\n",
              "  10516.575612825722,\n",
              "  10525.251947408065,\n",
              "  10524.775225727715,\n",
              "  10524.489192719506,\n",
              "  10514.001315751839,\n",
              "  10489.021099701573,\n",
              "  10478.247189725695,\n",
              "  10466.710525061259,\n",
              "  10468.808100454793,\n",
              "  10464.040883651307,\n",
              "  10459.75038852817,\n",
              "  10459.273666847821,\n",
              "  10458.796945167474,\n",
              "  10458.224879151056,\n",
              "  10458.415567823195,\n",
              "  10459.178322511752,\n",
              "  10457.843501806776,\n",
              "  10444.495294757016,\n",
              "  10431.242432043326,\n",
              "  10428.286757625165,\n",
              "  10402.543786886341,\n",
              "  10392.246598590811,\n",
              "  10391.197810894044,\n",
              "  10386.907315770908,\n",
              "  10382.330787639561,\n",
              "  10379.47045755747,\n",
              "  10388.814202492302,\n",
              "  10363.07123175348,\n",
              "  10369.936023950499,\n",
              "  10361.831755384572,\n",
              "  10327.698483071614,\n",
              "  10349.43699169551,\n",
              "  10354.204208498995,\n",
              "  10354.966963187553,\n",
              "  10392.53263159902,\n",
              "  10392.53263159902,\n",
              "  10402.543786886341,\n",
              "  10402.543786886341,\n",
              "  10454.411105708266,\n",
              "  10459.75038852817,\n",
              "  10459.55969985603,\n",
              "  10459.55969985603,\n",
              "  10487.781623332667,\n",
              "  10486.92352430804,\n",
              "  10487.876967668737,\n",
              "  10506.94583488268,\n",
              "  10506.85049054661,\n",
              "  10529.828475539412,\n",
              "  10524.870570063787,\n",
              "  ...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}